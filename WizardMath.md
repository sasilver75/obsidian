

Interesting in that it introduced the idea of using a [[Process Reward Model]] (PRM) as the reward model in [[Reinforcement Learning from Human Feedback|RLHF]] via [[Proximal Policy Optimization]] (PPO).