June 2021 -- [[Eleuther]] (~13 months after the release of [[GPT-3]])

A 6-B parameter English [[Decoder-Only Architecture]] language model trained on [[The Pile]]. Designed to serve as an open-source alternative to GPT-3, offering comparable performance on a range of natural language processing tasks despite being smaller in scale.

There wasn't a specific paper detailing GPT- -- instead, Eleuther provided some documentation and blog posts explaining the development 

