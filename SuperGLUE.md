
Succeeded [[GLUE]], which saturated (model > humans in < 1 year). SuperGLUE instead lasted a few years.

May 2019 benchmark for understanding Language Model performance on downstream tasks. Styled after [[GLUE]], but with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard.