---
aliases:
  - MDP
---
MDPs are an extension of [[Markov Chain]]s.
Related: Partially-Observable Markov Decision Process (POMDP) vs Fully-Observable MDPs

