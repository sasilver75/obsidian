December 4, 2023 (7mo after [[HuggingFace|HF]]+co's [[StarCoder]]), 6mo after [[Microsoft Research|MSR]]'s [[WizardCoder]])
UIUC/Tsinghua University
Paper: [Magicoder: Source Code is All You Need](https://arxiv.org/abs/2312.02120) ðŸŽ©ðŸª„âœ¨
#zotero 
Takeaway: Magicoder is a series of open-source 7B LMs (finetunes of CodeLlama-Python-7B) for code-generation powered by 75k instructions  generated by the [[OSS-Instruct]] technique (also from this paper), which hopes to generate more *diverse, realistic, and controllable* data. Authors stack the orthogonal [[Evol-Instruct]] method from [[WizardLM]]/[[WizardCoder]] to build an *enhanced* Magicoder$S$. 

Relevance: ...


Related:
- In some ways similar to [[Instruction Backtranslation]], in the sense that both in some sense take "inspiration" from already-existing code (rather than from set of seed tasks like in Self-Instruct, or some heuristics as in . The Instruction Backtranslation though treads that text as the response to an instruction, whereas this paper 
----

Small 7B code-generation models [[Instruction-Tuning|Instruction-Tuned]] on 75k instructions produced by the [[OSS-Instruct]] synthetic data generation technique developed for this paper.
- They note the *orthogonality* of [[OSS-Instruct]] and [[Evol-Instruct]], which enabled them to build an enhanced model. ==MagicoderS==.
- Magicoder and MagicoderS both outperform SoTA code models of similar size.

Notes:
- Existing techniques like Self-Instruct (which relies on 21 seed tasks to generate new instructions) or Evol-Instruct (which depends on 5 heuristics to depth-wise evolve the dataset) may result in models inheriting system biases inherent in the LLM or in the predefined tasks.
- Authors introduce ==OSS-Instruct== to mitigate the inherent biases of LLMs and via direct learning from open source -- it leverages powerful LLMs to automatically generate new coding problems by *drawing inspiration from any random snippets collected from open source.* (see figures for prompt)
	- Example; LLM gets "inspired" by two incomplete code fragments from different functions, and manages to relate them and craft a realistic machine learning problem.
	- Authors hope this is a *low bias* and *high-quality* was of generating instruction-tuning data. Notably they say that it's orthogonal to other methods, so they go on to combine it with Evol-Instruct to create MagicoderS.
- Generating Code
	- Authors use `starcoderdsata` as their seed corpus, a filtered version of [[The Stack]]. It includes massive high-quality code snippets, and is already preprocessed for data decontamination.
	- For each code document from the corpus, we randomly extract 1-15 consecutive lines as the seed snippet for the model -- in total, we collected 80k code snippets from 80k code documents (40k from Python, and 5k each from C++, Java, TypeScript, Shell, etc.). After data cleaning/deduplicating/benchmark decontamination, we end up with about 75k entries.
- Implementation Details
	- Data generation: We use `gpt-3.5-turbo-1106` as the foundation model to do OSS=Instruct. With 1-15 lines from a selected code document, we use greedy decoding to maximize consistency between generated problems and solutions
	- Data decontamination: We apply data decontamination before training our Magicoder and MagicoderS models.
	- Training: We employ `CodeLLaMA-Python-7B` and `DeepSeek-Coder-Base 6.7B` as the base LLMs, and fine-tune them on 75k synthetic data generated through OSS-Instruct. To obtain MagicoderS, we continue to finetune Magicoder models with the `evol-codealpaca-v1` dataset, an open-source [[Evol-Instruct]] implementation with 110k samples.


Abstract
> We introduce Magicoder, a ==series== of fully open-source (code, weights, and data) Large Language Models (LLMs) for code that ==significantly closes the gap with top code models while having no more than 7B parameters==. Magicoder models are ==trained on 75K synthetic instruction data using OSS-Instruct==, a novel approach to enlightening LLMs with open-source code snippets to generate high-quality instruction data for code. Our main motivation is to ==mitigate the inherent bias of the synthetic data generated by LLMs by empowering them with a wealth of open-source references for the production of more diverse, realistic, and controllable data==. The orthogonality of OSS-Instruct and other data generation methods like Evol-Instruct further enables us to build an enhanced MagicoderS. Both Magicoder and MagicoderS substantially outperform state-of-the-art code models with similar or even larger sizes on a wide range of coding benchmarks, including Python text-to-code generation, multilingual coding, and data-science program completion. Notably, MagicoderS-CL-7B based on CodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in pass@1). Overall, OSS-Instruct opens a new direction for low-bias and high-quality instruction tuning using abundant open-source references.

# Paper Figures
![[Pasted image 20240509174525.png]]
Above: The [[OSS-Instruct]] method!

![[Pasted image 20240509181757.png]]
Above: The prompt used for OSS-Instruct. 

![[Pasted image 20240509223637.png]]
Above: Problems and Solutions generated from  OSS-Instruct. Some details omitted.