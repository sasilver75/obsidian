---
aliases:
  - RLHF
---
March 4, 2022 -- [[OpenAI]]
Paper: [Training Language Models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)

See also: [[Reinforcement Learning from Human Feedback with AI Feedback]] (RLAIF)

Abstract
> 


![[Pasted image 20240415231812.png]]



![[Pasted image 20240418171453.png]]