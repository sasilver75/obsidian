Contrary to [[Batch Processing]], stream processing messages are generated by "producers," stored by a "broker," and then handled by a "consumer."

They are processed one at a time, as opposed to in a batch.


Use case:
- Asynchronous processing of application events
- Joining multiple data streams together
- Time-based grouping of data




In-Memory Message Broker
- We have a queue in memory,a nd remove messages hwen a consumers succesfsully reports that they were handled!
- Many message patterns supported, including [[Round Robin]] message delivery to consumers.
	- Con: We aren't necessarily processing all of these messages in order.
	- When messages are sent to a consumer, they're briefly removed from the topic... and put into a potentially-acknowledged area/staging area... and once it's actually acked, it gets deleted.
	- If we're too slo wto consume these messages, we might run out of memory on a broker.

Log-Based Message Broker, e.g. [[Kafka]]
- Messages are persisted sequentially on disk. Broker keeps track of each consumers last read offset in the event that it fails.
- Messages are **not deleted upon consumption**, and can be **replayed** down the line.
	- Messages are read in order of creation time when reading from a single [[Partition]]
	- To increase read/write throughput of the broker, we can create more partitions (since partition leaders in Kafka are the only ones that serve reads and writes)
	- If a consumer fails, it can resume at its last read offset.

Stream Processing: Stateful Consumer Frameworks, e.g. [[Flink]]
- When consuming from message brokers, it's frequently hte case that you needto build up some sort of state, like when we're doing ==time window aggregation== for messages in the last hour.
- It would stink if our consumer failed, and then all of those messages got lost!
- Depending on the type of message broker, we can re-consume/re-play those messages again and build up our state again.
	- This can still be expensive if it's the case that we've missed a ton of messages in the meantime, etc.
- So these consumers... in addition to supporting these aggregations/joins etc. is that they'll occasionally take their state and **checkpoint** it, along with their offset in the message broker, into some durable storage. 
	- So if we fail, we can start back up, read from that snapshot, and start again reading from the log-based message broker from the offset described in the checkpoint, using the cheeckpoint state, rather than having to read from the (e.g.) beginning of the log and re-establish state from zero.
