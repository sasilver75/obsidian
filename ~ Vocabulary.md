# Linear Algebra
- 


# Probability/Statistics
- ******


# Information Retrieval
- [[BM25]]
- [[Hierarchical Navigable Small World]]
- [[Locality Sensitive Hashing]]


# Supervised/Unsupervised Learning Concepts
- [[Machine Learning]]
- [[Supervised Learning]]
- [[Unsupervised Learning]]
- [[Overfitting]]
- [[K-Shot Learning]] / [[In-Context Learning]]
- [[Feed-Forward Network]]
- [[Chain of Thought]] ([[CoT]])
- [[Catastrophic Forgetting]]
- [[Reinforcement Learning for Human Feedback]]
	- [[Rejection Sampling]] in the RLHF context
- [[Fine-Tuning]]
- [[Instruction-Tuning]]
- [[Transfer Learning]]
- [[Retrieval-Augmented Generation]]
- [[Autoencoders]]
- [[Variational Autoencoder]]
- Beta-VAE
- [[Regularization]]
	- [[L1 Regularization]]
	- [[L2 Regularization]]
- [[Ensemble Learning]]
- [[Attention]] Mechanism
	- [[Self-Attention]]
	- [[Multi-Head Attention]]
	- [[Masked Attention]]
	- [[Sparse Attention]]
	- [[Cross Attention]]
- [[Diffusion Models]]
- [[Low-Rank Adaptation]], [[Parameter-Efficient Fine-Tuning]]
- [[Semantic Segmentation]]
- [[Quantization]]
- [[Model Pruning]]
- [[Masking]]
- [[Supervised Learning]]
- [[Unsupervised Learning]]
- [[Semi-Supervised Learning]]
- [[Reinforcement Learning]]
- [[Embeddings]]
- [[Positional Encoding]]
- [[Tokens]]
- [[Numericalization]]
- [[Pre-training]]
- [[Fine-Tuning]]
- [[Batch Normalization]]
- [[Layer Normalization]]
- [[Convolution]]
- [[Grouped Convolutions]]
- [[Depth-Wise Convolutions]]
- [[Activation Function]]
- [[Sigmoid Activation Function]]
- [[Tanh Activation Funcition]]
- [[ReLU Activation Function]]
- [[U-Net]]
- [[ULMFit]]
- [[Gini Index]]
- [[Test-Time Augmentation]]
- [[Gradient Accumulation]]
- [[One-Hot Encoding]]
- [[Recurrent Neural Networks]]
- [[Bi-Directional Recurrent Neural Network]]
- [[Long Short Term Memory]]
- [[Gated Recurrent Unit]]
- [[Convolutional Neural Network]]
- [[Region-Based Convolutional Neural Network]]
- [[Vanishing Gradients]], [[Exploding Gradients]]
- [[Encoder-Decoder Architecture]]
- [[Masked Language Model]]
- [[Knowledge Distillation]]
- [[Hallucination]]
- [[Inductive Bias]]
- [[Graph Convolutional Network]]
- [[Mode Collapse]] 
- [[VC Dimension]]
- [[Alignment Tax]]
- [[Perplexity]] 
- [[Curriculum Learning]]
- [[Online Learning]]
- [[Precision]] 
- [[Recall]] 
- [[Label-free Evaluations]] vs [[Labeled Evaluations]]
- [[Generative Adversarial Network]]
- [[Adam Optimizer]]
- [[RMSProp Optimizer]]
- [[Residual Connection]]
- [[Transformer]]
- [[Neural Architecture Search]]
- [[Out-of-Vocabulary Token]]
- [[Double Descent]]
- [[Bias-Variance Tradeoff]]
- [[Guardrails]], [[Steerability]]
- [[Class Token]] 
- [[Contrastive learning]] / [[Contrastive Loss]]
- [[Pre-text Training]] 
- [[Monte-Carlo Tree Search]]
- [[Markov Chain]] 
- [[Beam Search]]
- [[Kalman Filter]]
- [[Exposure Bias]]
- [[Covariate Shift]]
- [[Particle Filters]] 
- [[Gaussian Splatting]]
- [[Neural Radiance Fields]]
- [[Tree of Thought]]
- [[VLM]] 
- [[Speculative Decoding]]
- [[Dropout]]
- [[Label Smoothing]]
- [[Direct Policy Optimization]]
- [[Sampled Softmax]]
- [[Positive Pair]]
- [[Negative Pair]]


# Natural Language Processing Concepts
- [[Sentiment Analysis]]
- [[Argument Mining]]
- [[Computational Social Science]] / [[Cultural Analytics]]
- [[Language Grounding]]
- [[Question Answering]]
- [[Machine Translation]]
- [[Information Extraction]]
- [[Byte-Pair Encoding]]


# Reinforcement Learning Concepts
- [[Reinforcement Learning]]
- [[Agent]]
- [[Policy]]
- [[Hierarchical Reinforcement Learning]]
- [[Inverse Reinforcement Learning]]
- [[Q-Function]]
- [[Q-Learning]], [[Deep Q Networks]]
- [[Policy Gradient Algorithm]]
- [[Value Learning]] vs [[Policy Learning]]
- [[Proximal Policy Optimization]]
- [[Bellman Equation]]
- [[Temporal Difference Learning]] (TD-Learning)
- Compute-Optimal Training
- Inference-Optimal Training


# Models, Datasets, Techniques
- [[LeNet]]
- [[AlexNet]]
- [[CLIP]] 
- [[BERT]]
- [[GPT]]
	- [[GPT-1]]
	- [[GPT-2]]
	- [[GPT-3]]
	- [[InstructGPT]]
	- [[GPT-4]]
- [[Word2Vec]]
- [[GloVe]]
- [[ConvNext]]
- [[Residual Network]]
- [[Segment Anything Model]]
- [[YOLOv3]]
- [[DistillBert]]
- [[XLNET]]
- [[T5]]
- [[Stable Diffusion]]
- [[Llama]]
- [[Llama2]]
- [[Retro]]
- [[Chinchilla]]
- [[ControlNet]]
- [[VGG]]


# Tools
- [[ComfyUI]]
- [[Automatic1111]] 
- [[Axolotl]]
- [[Oogabooga]]
- [[Eleuther LM Evaluation Harness]]
- [[Gradio]]
- [[Streamlit]]
- [[MergeKit]]
- [[GGUF]] File Format


# Benchmarks
- [[GAIA]]: A benchmark for General AI Assistants
- [[Massive Multi-task Language Understanding]] ([[Massive Multi-task Language Understanding|MMLU]])
- [[HumanEval]]


# Datasets
- [[CommonCrawl]]
- [[C4]] (improvement of CommonCrawl)
- [[Webtext]], OpenWebtext2
- [[The Stack]]
- [[The Pile]]
- [[LAION]]
- [[Whisper]]
- Dataset Problems:
	- Code when duplicated multiple times in a dataset means that it's going to be trained on more than other data. According to LatentSpace101Datsets ep, it increases the likelihood disproportionately -- eg 2x the occurrences in the data may mean that there's a 100x likelihood of it being reproduced.
- CIFAR-10
- MNIST
- TinyStories

# Companies

Dataset Types
- Raw Internet
	- Common Crawl, Wikipedia
- Demonstrations
	- Demonstrating ideal assistant response (prompt/response pairs for assistant)
- Comparisons
	- Output A and B, which is better?
- Reinforcement learning with prompts


