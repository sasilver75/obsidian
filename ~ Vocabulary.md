# Linear Algebra
- 


# Probability/Statistics
- [[Monte-Carlo Tree Search]]
- 


# Information Retrieval
- [[BM25]]
- [[Hierarchical Navigable Small Worlds]]
- [[Locality Sensitive Hashing]]
- [[Reranking]]

# Data Analytics
- [[Type One Error]]
- [[Type Two Error]]
- [[Precision]]
- [[Recall]]
- [[Covariate Shift]]
- [[Regularization]]
- [[One-Hot Encoding]]
- [[t-SNE]]
- [[Bootstrap]]
- [[Bootstrap Aggregation]]
- [[Hidden Markov Model]]
- [[Markov Chain]]
- [[Beam Search]]

# RecSys
- [[Collaborative Filtering]]
- [[Content-Based Filtering]]


# Supervised/Unsupervised Learning Concepts
- [[Machine Learning]]
- [[Supervised Learning]]
- [[Unsupervised Learning]]
- [[Overfitting]]
- [[Prompting]]/[[K-Shot Learning]] / [[In-Context Learning]]/[[Few-Shot Learning]]
- [[Feed-Forward Network]]
- [[Chain of Thought]] ([[CoT]])
- [[Catastrophic Forgetting]]
- [[Reinforcement Learning for Human Feedback]]
	- [[Rejection Sampling]] in the RLHF context
- [[Fine-Tuning]]
- [[Instruction-Tuning]]
- [[Transfer Learning]]
- [[Retrieval-Augmented Generation]]
- [[Autoencoder]]
- [[Ensemble Learning]]
- [[Attention]] Mechanism
- [[Diffusion Models]]
- [[Parameter-Efficient Fine-Tuning]]
- [[Semantic Segmentation]]
- [[Quantization]]
- [[Model Pruning]]
- [[Masking]]
- [[Supervised Learning]]
- [[Unsupervised Learning]]
- [[Semi-Supervised Learning]]
- [[Reinforcement Learning]]
- [[Embeddings]]
- [[Positional Encoding]]
- [[Tokens]]
- [[Numericalization]]
- [[Pre-training]]
- [[Fine-Tuning]]
- [[Batch Normalization]]
- [[Layer Normalization]]
- [[Convolution]]
- [[Grouped Convolutions]]
- [[Depth-Wise Convolutions]]
- [[Activation Function]]
- [[U-Net]]
- [[ULMFit]]
- [[Gini Index]]
- [[Test-Time Augmentation]]
- [[Gradient Accumulation]]
- [[Recurrent Neural Networks]]
- [[Bi-Directional Recurrent Neural Network]]
- [[Long Short Term Memory]]
- [[Gated Recurrent Unit]]
- [[Convolutional Neural Network]]
- [[Region-Based Convolutional Neural Network]]
- [[Vanishing Gradients]], [[Exploding Gradients]]
- [[Masked Language Model]]
- [[Knowledge Distillation]]
- [[Hallucination]]
- [[Inductive Bias]]
- [[Graph Convolutional Network]]
- [[Mode Collapse]] 
- [[VC Dimension]]
- [[Alignment Tax]]
- [[Perplexity]] 
- [[Curriculum Learning]]
- [[Online Learning]]
- [[Label-free Evaluations]] vs [[Labeled Evaluations]]
- [[Generative Adversarial Network]]
- [[Adam Optimizer]]
- [[RMSProp Optimizer]]
- [[Residual Connection]]
- [[Transformer]]
- [[Encoder-Decoder Architecture]]
- [[Neural Architecture Search]]
- [[Out-of-Vocabulary Token]]
- [[Double Descent]]
- [[Bias-Variance Tradeoff]]
- [[Guardrails]], [[Steerability]]
- [[Class Token]] 
- [[Contrastive learning]] / [[Contrastive Loss]]
- [[Pre-text Training]] 
- [[Kalman Filter]]
- [[Exposure Bias]]
- [[Particle Filters]] 
- [[Gaussian Splatting]]
- [[Neural Radiance Fields]]
- [[Tree of Thought]]
- [[VLM]] 
- [[Speculative Decoding]]
- [[Dropout]]
- [[Label Smoothing]]
- [[Direct Policy Optimization]]
- [[Sampled Softmax]]
- [[Positive Pair]]
- [[Negative Pair]]
- [[Mode Collapse]]
- [[Active Learning]]


# Natural Language Processing Concepts
- [[Sentiment Analysis]]
- [[Argument Mining]]
- [[Language Grounding]]
- [[Question Answering]]
- [[Machine Translation]]
- [[Information Extraction]]
- [[Byte-Pair Encoding]]


# Reinforcement Learning Concepts
- [[Reinforcement Learning]]
- [[Agent]]
- [[Policy]]
- [[Hierarchical Reinforcement Learning]]
- [[Inverse Reinforcement Learning]]
- [[Q-Function]]
- [[Q-Learning]], [[Deep Q Networks]]
- [[Policy Gradient Algorithm]]
- [[Value Learning]] vs [[Policy Learning]]
- [[Proximal Policy Optimization]]
- [[Bellman Equation]]
- [[Temporal Difference Learning]] (TD-Learning)
- Compute-Optimal Training
- Inference-Optimal Training


# Models, Techniques
- [[LeNet]]
- [[AlexNet]]
- [[CLIP]] 
- [[BERT]]
- [[GPT]]
	- [[GPT-1]]
	- [[GPT-2]]
	- [[GPT-3]]
	- [[InstructGPT]]
	- [[GPT-4]]
- [[Word2Vec]]
- [[GloVe]]
- [[ConvNext]]
- [[Residual Network]]
- [[Segment Anything Model]]
- [[T5]]
- [[Stable Diffusion]]
- [[Llama]]
- [[Llama2]]
- [[Chinchilla]]
- [[ControlNet]]
- [[VGG]]
- [[Phi]]
- [[Flamingo]]
- [[ViT]]
- [[YOLO]]
- [[U-Net]]
- [[Inception]]
- [[Latent Dirichlet Allocation]]
- [[Random Forest]]
- [[Support Vector Machine]]
- [[Gato]]
- [[Whisper]]
- [[ReAct]]
- [[PaLM]]
- [[FLAN]]
- [[DALL-E]]
- [[DINO]]
- [[Reinforcement Learning from Human Feedback]]
- [[Low-Rank Adaptation]]

# Tools
- [[ComfyUI]]
- [[Automatic1111]] 
- [[Axolotl]]
- [[Oogabooga]]
- [[Eleuther LM Evaluation Harness]]
- [[Gradio]]
- [[Streamlit]]
- [[MergeKit]]
- [[GGUF]] File Format
- [[Ludwig]]


# Benchmarks
- [[GAIA]]: A benchmark for General AI Assistants
- [[Massive Multi-task Language Understanding]] ([[Massive Multi-task Language Understanding|MMLU]])
- [[HumanEval]]
- [[BIG-Bench]]


# Datasets
- [[CommonCrawl]]
- [[C4]] (improvement of CommonCrawl)
- [[Webtext]], OpenWebtext2
- [[The Stack]]
- [[The Pile]]
- [[LAION]]
- [[Whisper]]
- Dataset Problems:
	- Code when duplicated multiple times in a dataset means that it's going to be trained on more than other data. According to LatentSpace101Datsets ep, it increases the likelihood disproportionately -- eg 2x the occurrences in the data may mean that there's a 100x likelihood of it being reproduced.
- [[CIFAR-10]]
- [[MNIST]]
- [[TinyStories]]
- [[LAION]]
	- LAION-COCO
- [[MMC4]] (Multimodal C4)

# Companies and Research Labs
- [[Cohere]]
- [[OpenAI]]
- [[Anthropic]]
- [[Google Brain]]
- [[Hugging Face]]
- [[Cohere]]
- [[Inflection]]
- [[Deepmind]]
- [[Allen Institute]]
- [[Microsoft Research]]
- [[Stanford AI Lab]]
- [[Berkeley AI Research Lab]]
- [[Snorkel]]