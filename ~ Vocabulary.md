# Data Engineering
- [[Apache Arrow]]

# Linear Algebra
- [[Vector]]
- [[Span]]
- [[Rank (Linear Algebra)]]
- [[Column Space]]
- [[Row Space]]
- [[Dot Product]]
- [[Cross Product]]
- [[Cosine Similarity]]
- [[Eigenvector]]
- [[Eigenvalue]]
- [[Determinant]]
- [[Singular Value Decomposition]]
- [[Row Echelon Form]]  (+Reduced Row Echelon Form)
- [[Inverse]]
- [[Transpose]] (and Symmetric matrices)

# Probability/Statistics
- [[Law of Large Numbers]]
- [[Central Limit Theorem]]
- [[Monte-Carlo]]
- [[Markov Assumption]] (Markov Property)
- [[Hidden Markov Model]] (HMM)
- [[Markov Chain]] (Markov Process)
- [[Markov Chain Monte Carlo]] (MCMC)
- [[Importance Sampling]]
- [[Pearson Correlation Coefficient]]
- [[Spearman Correlation Coefficient]]
- [[Kendall Rank Correlation Coefficient]]
- [[Chi-Squared]]
- [[Multicollinearity]]
- [[Degrees of Freedom]]
- [[Hyperparameter]]
- [[Loss Function]]
- [[Bandit]]
- [[Multi-Armed Bandit]]

# Analytics/Misc. Modeling
- [[Type One Error]]
- [[Type Two Error]]
- [[Precision]]
- [[Recall]]
- [[Covariate Shift]]
- [[Regularization]]
	- [[L1 Regularization]]
	- [[L2 Regularization]] ([[L2 Regularization|Weight Decay]])
- [[Consistency Regularization]]
- [[One-Hot Encoding]]
- [[t-SNE]]
- [[Bootstrap]]
- [[Bootstrap Aggregation]]
- [[Beam Search]]
- [[F1 Score]]
- [[ROC Curve]] (Received Operating Characteristic)
- [[ROC-AUC]] (ROC Area under Curve)
- [[Precision-Recall Curve]] (PR Curve)
- [[PR-AUC]] (PR Area under Curve)
- [[JS Divergence]] (Jensen-Shannon Divergence)
- [[Principal Component Analysis]] (PCA)
- [[Independent Component Analysis]] (ICA)
- [[Bloom Filter]]
- [[Count-Min Sketch]]
- [[MinHash]]
- [[Monte-Carlo Tree Search]]
- [[Bias-Variance Tradeoff]]
- [[XGBoost]]
- [[K-Means Clustering]]
- [[K-Nearest Neighbors]] (kNN) 
- [[Naive Bayes]]
- [[Gradient Boosting Machine]] (GBM)
- [[Classification]]
- [[Collaborative Filtering]]
- [[Content-Based Filtering]]
- [[Training Dataset]]
- [[Validation Dataset]]
- [[Test Dataset]]
- [[Cross-Validation]]
- [[UMAP]]
- [[DBSCAN]]
- [[Cloze]]
- [[Inverse Cloze]]
- [[Decision Tree]]
- [[Random Forest]]
- [[Support Vector Machine]]
- [[Jaccard Similarity]]
- [[Hamming Distance]]
- [[Manhattan Distance]]
- [[Goodhardt's Law]]
- [[Outlier Detection]]
- [[Coreset Selection]]

# Machine Learning/General
- [[Graph Neural Network]]
- [[Long Short Term Memory]] (LSTM)
- [[Gradient Clipping]]
- [[Data Augmentation]]
- [[Gradual Unfreezing]]
- [[Discriminative Learning Rate]]
- [[Gated Recurrent Unit]] (GRU)
- [[In-Context Learning]]
- [[Few-Shot Prompting]]
- [[Teacher Forcing]] vs [[Student Forcing]]
- [[Bitter Lesson]]
- [[Self-Supervised Learning]]
- [[Alignment]]
- [[Kullback-Leibler Divergence]] (KL Divergence)
- [[Entropy]]
- [[Mutual Information]]
- [[Cross-Entropy]]
- [[Seq2Seq]]
- [[Perplexity]] 
- [[Bits-per-Character]] (BPC)
- [[Bits-per-Word]] (BPW)
- [[Weight Tying]]
- [[Large Language Model]]
- [[Foundation Model]]
- [[Multimodal]]
- [[VLM]] (Vision-Language Model)
- [[Machine Learning]]
- [[Softmax]]
- [[Rectified Linear Unit|ReLU]] (Rectified Linear Unit)
- [[Leaky ReLU]]
- [[Tanh]]
- [[SwiGLU]] ([[Swish]] + GLU)
- [[Overfitting]]
- [[Underfitting]]
- [[Epoch]]
- [[Feature Engineering]]
- [[Prompting]]
- [[Prompt Tuning]]
- [[Feed-Forward Network]] (FFNN)
- [[Chain of Thought]] (CoT)
- [[Chain of Note]] (CoN)
- [[Catastrophic Forgetting]]
- [[Fine-Tuning]]
- [[Instruction-Tuning]]
- [[Preference-Tuning]]
- [[Transfer Learning]]
- [[Autoencoder]]
- [[Variational Autoencoder]] (VAE)
- [[Beta-VAE]]
- [[Ensemble Learning]]
- [[Attention]] Mechanism
- [[Self-Attention]]
- [[Cross-Attention]]
- [[Bidirectional Attention]]
- [[Sparse Attention]]
- [[Diffusion Model]]
- [[Latent Diffusion Model]]
- [[Latent Consistency Model]]
- [[Parameter-Efficient Fine-Tuning]] (PEFT)
- [[Adapter]]
- [[Adapter Fusion]]
- [[Quantization]]
- [[Quantization-Aware Training]] (QAT)
- [[Post-Training Quantization]] (PTQ)
- [[Model-Aware Quantization]]
- [[Activation-Aware Weight Quantization]] (AWQ)
- [[Model Pruning]]
- [[Structured Pruning]]
- [[Magnitude Pruning]]
- [[Masking]]
- [[Supervised Learning]]
- [[Unsupervised Learning]]
- [[Semi-Supervised Learning]]
- [[Weak Supervision]]
- [[Confident Learning]]
- [[Embedding]]
- [[Token]]
- [[Numericalization]]
- [[Pre-training]]
- [[AdaBoost]]
- [[Batch]]
- [[Batch Normalization]] (BatchNorm)
- [[Layer Normalization]] (LayerNorm)
- [[Convolution]]
- [[Grouped Convolutions]]
- [[Depth-Wise Convolutions]]
- [[Activation Function]]
- [[Gini Index]]
- [[Test-Time Augmentation]]
- [[Gradient Accumulation]]
- [[Recurrent Neural Network]] (RNN)
- [[Long Short Term Memory]] (LSTM)
- [[Gated Recurrent Unit]] (GRU)
- [[Convolutional Neural Network]]
- [[Region-Based Convolutional Neural Network]] (R-CNN)
- [[Vanishing Gradients]], [[Exploding Gradients]]
- [[Distillation]]
- [[Context Distillation]]
- [[Self-Distillation]]
- [[Hallucination]]
- [[Inductive Bias]]
- [[Reward Model]] (RM)
- [[Pairwise Ranking]] vs [[Direct Assessment]]
- [[Process Reward Model]] (PRM)
- [[Bradley-Terry Model]]
- [[Graph Convolutional Network]]
- [[Mode Collapse]] 
- [[VC Dimension]]
- [[Alignment Tax]]
- [[Curriculum Learning]]
- [[Online Learning]]
- [[Weak-to-Strong Generalization]]
- [[Label-free Evaluations]] vs [[Labeled Evaluations]]
- [[Generative Adversarial Network]]
- [[Adam]]
- [[RMSProp]]
- [[Adagrad]]
- [[Residual Connection]]
- [[bfloat16]]
- [[Transformer]]
- [[Encoder-Only Architecture]]
- [[Decoder-Only Architecture]]
- [[Encoder-Decoder Architecture]]
- [[Neural Architecture Search]]
- [[Double Descent]]
- [[Guardrails]], [[Steerability]]
- [[Class Token]] 
- [[Contrastive Loss]]
- [[Pre-text Training]] 
- [[Kalman Filter]]
- [[Particle Filters]] 
- [[Gaussian Splatting]]
- [[Neural Radiance Fields]] (NeRF)
- [[Tree of Thought]] (ToT)
- [[VLM]] 
- [[Continuous Batching]]
- [[Speculative Decoding]]
- [[Speculative Sampling]]
- [[Constrained Decoding]]
- [[Reward-Augmented Decoding]]
- [[Human-in-the-Loop Decoding]]
- [[Dropout]]
- [[Label Smoothing]]
- [[Sampled Softmax]]
- [[Positive Pair]]
- [[Negative Pair]]
- [[Mode Collapse]]
- [[Active Learning]]
- [[Prior Amplification]]
- [[Prefix Tuning]]
- Compute-Optimal Training
- Inference-Optimal Training
- [[Low-Rank Adaptation]] (LoRA)
- [[Quantized Low-Rank Adaptation]] (QLoRA)
- [[Weight-Decomposed Low-Rank Adaptation]] (DoRA)
- [[Scaling Laws]]
- [[Synthetic Data]]
- [[Mixture of Experts]] (MoE)
- [[Soft Mixture of Experts]] (sMoE)
- [[Mixture-of-Depths]] (MoD)
- [[Model Parallelism]]
- [[Tensor Parallelism]]
- [[Fully Sharded Data Parallelism]]
- [[RMSNorm]] (Root Mean Square Layer Normalization)
- [[Gradient Checkpointing]]
- [[Rotary Positional Embedding]] (RoPE)
- [[LongRoPE]]
- [[YaRN]] (Yet another RoPE extensioN method)
- [[Attention with Linear Biases]] (ALiBi)
- [[Self-Play Fine-Tuning]] (SPIN)
- [[Canary GUID]]
- [[Early Stopping]]
- [[Learning Rate]]
- [[Grouped Query Attention]]
- [[RingAttention]]
- [[Evol-Instruct]]
- [[Evol-Amplify]]
- [[OSS-Instruct]]
- [[Imitation Learning]]
- [[Automatic Mixed-Precision Training]]
- [[Xavier Initialization]]
- [[He Initialization]]
- [[Out-of-Bag Error]]
- [[Boosting]]
- [[Direct Preference Optimization]] (DPO)
- [[Conservative Direct Preference Optimization]] (cDPO)
- [[Identity-Mapping Preference Optimization]] (IPO)
- [[Binary Classifier Optimization]] (BCO)
- [[Kahneman-Tversky Optimization]] (KTO)
- [[Direct Nash Optimization]] (DNO)
- [[Stepwise Direct Preference Optimization]] (sDPO)
- [[Odds Ratio Preference Optimization]] (ORPO)
- [[Trust Region Policy Optimization]] (TRPO)
- [[Self-Consistency]]
- [[Self-Ask]]
- [[Self-RAG]]
- [[Self-Discover]]
- [[KV Cache]]
- [[Negative Prompt]]
- [[LLM-as-a-Judge]]
- [[Positional Bias]]
- [[Verbosity Bias]]
- [[Self-Enhancement Bias]]
- [[Continual Pretraining]]
- [[False Refuse]]
- [[Lottery Ticket Hypothesis]]
- [[Retrieval-Augmented Generation]] (RAG)
- [[Retrieval-Augmented Generation (Model)]] (RAG)
- [[CRAG|Corrective Retrieval Augmented Generation]] (CRAG)
- [[Instruction Backtranslation]]
- [[CRINGE Loss]]
- [[Hinge Loss]]
- [[Pairwise Cringe Optimization]] (PCO)
- [[Maximum Inner Product Search]] (MIPS)
- [[Reinforced Self-Training]] (ReST/$ReST^{EM}$)
- [[Rejection Sampling]]
- [[Best-of-N Sampling]]

# Information Retrieval Concepts
- [[TF-IDF]]
- [[BM25]]
- [[Hierarchical Navigable Small Worlds]] (HNSW)
- [[Locality Sensitive Hashing]] (LSH)
- [[Inverted File Index]] (IVF)
- [[Asymmetric Distance Computation]] (ADC)
- [[Product Quantization]] (PQ)
- [[Optimized Product Quantization]] (OPQ)
- [[Reranking]]
- [[Inverted Index]]
- [[Rank (Information Retrieval)]]
- [[Sparse Retrieval]]
- [[Dense Retrieval]]
- [[Hybrid Search]]
- [[Dense Passage Retrieval]] (DPR)
- [[ColBERT]]
- [[ColBERT-QA]]
- [[Baleen]]
- [[ColBERTv2]]
- [[PLAID]]
- [[Cumulative Gain]]
- [[Discounted Cumulative Gain]]
- [[Precision (Information Retrieval)]]
- [[Recall (Information Retrieval)]]
- [[Cross-Encoder]]
- [[HyDE]]
- [[Reverse HyDE]]
- [[Approximate Nearest Neighbor Search]]
- [[Late Interaction]]
- [[SPLADE]]
- [[SPLADEv2]]
- [[DRAGON]] (Dense Retrieval trained with Diverse Augmentation)
- [[TART]] (Task-Aware Retrieval with Instructions)
- [[SANTA]] (Structure-Aware Dense Retrieval)
- [[Fusion-in-Decoder]] (FiD)
	- [[KG-FiD]] (Knowledge Graph - Fusion in Decoder)
- [[RETRO]] (Retrieval-Enhanced Transformer)
- [[REALM]] (Retrieval-Augmented Language Model Pretraining)
- [[ORQA]] (Open-Retrieval Question Answering System)
- [[FLARE]] (Forward-Looking Active Retrieval Augmented Generation)
- [[CRAG]] (Corrective Retrieval Augmented Generation)
- [[Success]]
- [[Reciprocal Rank]]
- [[Mean Reciprocal Rank]]
- [[Normalized Discounted Cumulative Gain]] (NDCG)
- [[Mean Average Precision]] (MAP)
- [[Return Set]]
- [[Relevance Set]]
- [[Average Precision]]
- [[Promptagator]]
- [[Iterative Retrieval]]
- [[Recursive Retrieval]]
- [[Adaptive Retrieval]]
- [[Context Compression]]
- [[Query Expansion]]
- [[Iter-RetGen]]
- [[Tree of Clarification]]
- [[IRCoT]]
- Generate-Read, Recite-Read, Rewrite-Retrieve-Read, ...
- [[Relevance-Guided Supervision]]
- [[Hard Negative Mining]]
- [[Contriever]]
- [[Consistency Filtering]]
- [[InPars]] (Inquisitive Parrots for Search)
- [[UPR]] (Unsupervised Passage Re-Ranker)
- [[Generate-then-Read]] (GenRead)
- [[Approximate Nearest Neighbor Contrastive Learning]] (ANCE)

# Natural Language Processing Concepts
- Tasks
	- [[Sentiment Analysis]]
	- [[Argument Mining]]
	- [[Language Grounding]]
	- [[Question Answering]] (QA)
		- [[Open-Domain]]
		- [[Closed-Domain]]
		- [[Open-Book]]
		- [[Closed-Book]]
		- [[Multi-Hop]]
	- [[Machine Translation]] (MT)
	- [[Information Extraction]]
	- [[Diarization]]
	- [[Topic Modeling]]
	- [[Summarization]]
		- [[Extractive Summarization]]
		- [[Abstractive Summarization]]
	- [[Named Entity Recognition]] (NER)
	- [[Part-of-Speech Tagging]]
	- [[Parsing]]
	- [[Coreference Resolution]]
	- [[Semantic Text Similarity]] (STS)
- [[Context-Free Grammar]]
- [[Dependency Grammar]]
- [[Prosody]]
- [[Padding]]
- [[Back-Translation]]
- [[BLEU]] Score
- [[BLEURT]] Score
- [[ROUGE]] Score
- [[COMET]] Score
- [[BERTScore]]
- [[chrF]]
- [[Automatic Speech Recognition]]
- [[Byte-Pair Encoding]] Tokenization
- [[SentencePiece]] Tokenization
- [[WordPiece]] Tokenization
- [[Unigram Tokenization]]
- [[Self-Play]]
- [[Self-Correct]]
- [[Self-Instruct]]
- [[Web Rephrase Augmented Pre-training]] (WRAP) (Rephrasing the Web)
- [[GenQA]]
- [[Self-Reward]]
- [[Constitutional AI]]
- [[Zero-Shot Prompting]]
- [[Step-Back Prompting]]
- [[Least-to-Most Prompting]]
- [[Plan-and-Solve Prompting]]
- [[Masked Language Model]]
- [[U-Net]]
- [[Matryoshka Representation Learning]]
- [[Bi-Encoder]]
- [[Out-of-Vocabulary Token]] / "UNK"
- [[Greedy Decoding]]
- [[Ancestral Sampling]]
- [[Contrastive Decoding]]
- [[Top-K Sampling]]
- [[Top-P Sampling]] (Nucleus Sampling)
- [[Exposure Bias]]
	- [[Scheduled Sampling]]
	- [[Dataset Aggregation]]
- [[Temperature]]
- [[ReAct]]
- [[DSPy]]
- [[MIPRO]]
- [[N-Gram]]
- [[Coreference]], [[Coreference Resolution]]
- [[Selective Language Modeling]] (SLM)
- [[Noise-Contrastive Estimation]]
- [[InfoNCE]]

# Computer Vision Concepts
- [[Object Recognition]]
- [[Segmentation Mask]]
- [[Zero Padding]]
- [[Same Padding]]
- [[Max Pooling]]
- [[Average Pooling]]
- Tasks:
	- [[Image Segmentation]]
	- [[Semantic Segmentation]]
	- [[Panoptic Segmentation]]
	- [[Instance Segmentation]]
	- [[Image Classification]]
	- [[Image Captioning]]
	- [[Object Detection]]
	- [[Video Classification]]
	- [[Depth Estimation]]
	- Image-to-Image synthesis
	- Unconditional image generation
	- Conditional image generation
	- Image-to-Text (eg [[Optical Character Recognition]])
	- Text-to-Image
	- [[Visual Question-Answering]]
- [[Swin|Swin Transformer]]
- [[Vision Transformer]] (ViT)

# MultiModal Concepts
- Early Fusion, Middle Fusion, Late Fusion
- Representation Fusion
- Representation Coordination
- Representation Fission
- Single Stream vs Dual Stream

# Data Augmentation Concepts
- [[MixUp]]
- [[MixMatch]]
- [[Progressive Resizing]]

# Reinforcement Learning Concepts
- [[Reinforcement Learning]] (RL)
- [[Credit Assignment Problem]]
- [[Agent]]
- [[Reward]]
- [[Return]]
- [[Policy]]
- [[Deep Reinforcement Learning]]
- [[Value Function]]
- [[Trajectory]]
- [[Value Iteration]]
- [[Policy Iteration]]
- [[Policy Evaluation]]
- [[Dynamic Programming]]
- [[Hierarchical Reinforcement Learning]]
- [[Inverse Reinforcement Learning]]
- [[Q-Function]]
- [[Q-Learning]], [[Deep Q-Learning]]
- [[Deep Q-Networks]]
- [[Value Learning]] vs [[Policy Learning]]
- [[Proximal Policy Optimization]] (PPO)
- [[Group Relative Policy Optimization]] (GRPO)
- [[Bellman Equation]] 
- [[Monte-Carlo Learning]]
- [[Temporal Difference Learning]] (TD-Learning)
- [[TD-Lambda]]
- Actor-Critic methods
- [[Experience Replay]]
- [[Markov Reward Process]]
- [[Markov Decision Process]]
- [[REINFORCE]]
- [[SARSA]]
- [[SARSA-Lambda]]
- [[Advantage Function]]
- [[On-Policy]]
- [[Off-Policy]]
- [[Model-Based]]
- [[Model-Free]]
-  [[Reinforcement Learning from from AI Feedback]]
-  [[Reinforcement Learning from Human Feedback]]
- [[Epsilon-Greedy]]

# Models
- [[AlphaGo]]
- [[LeNet]]
- [[Falcon]]
- [[Falcon 2]]
- [[AlexNet]]
- [[CLIP]] 
- [[OpenCLIP]]
- [[BLIP]]
- [[BLIP-2]]
- [[SigLIP]]
- [[OWL]] (Multimodal)
- [[OWLSAM]]
- [[KOSMOS]]
- [[KOSMOS 2]]
- [[KOSMOS 2.5]]
- [[PaliGemma]]
- [[Bidirectional Encoder Representations from Transformers]] ([[Bidirectional Encoder Representations from Transformers|BERT]])
- [[Sentence-BERT]] ([[Sentence-BERT|sBERT]])
- [[DistilBERT]]
- [[RoBERTa]]
- [[ELECTRA]]
- [[BART]]
- [[DistilBART]]
- [[DeBERTa]]
- [[GPT-2]]
- [[GPT-3]]
- [[InstructGPT]]
- [[ChatGPT]]
- [[GPT-3.5]]
- [[GPT-4]]
- [[GPT-4V]]
- [[GPT-4o]]
- [[Megatron]]
- [[Word2Vec]]
	- [[Skip-Gram]]
	- [[Continuous Bag of Words]] (CBOW)
- [[GloVe]]
- [[ConvNext]]
- [[Residual Network]]
- [[Segment Anything Model]]
- [[T5]]
- [[Transformer-XL]]
- [[Compressive Transformer]]
- [[Stable Diffusion]]
- [[LLaMA]]
- [[LLaMA 2]]
- [[LLaMA 3]]
- [[LLaMA Guard]]
- [[LLAMA Guard 2]]
- [[Chinchilla]]
- [[ControlNet]]
- [[VGGNet]]
- [[TinyStories]] (Prequel to Phi models)
- [[Phi-1]]
- [[Phi-1.5]]
- [[Phi-2]]
- [[Phi-3]]
- [[Flamingo]]
- [[YOLO]]
- [[U-Net]]
- [[Inception]]
- [[Latent Dirichlet Allocation]]
- [[Gato]]
- [[Whisper]]
- [[PaLM]]
- [[FLAN]]
- [[FLAN-T5]]
- [[DALL-E]]
- [[DALL-E 2]]
- [[DALL-E 3]]
- [[DINO]]
- [[DINOv2]]
- [[Claude]]
- [[Gemeni]]
- [[Gemma]]
- [[Alpaca]]
- [[Vicuna]]
- [[Koala]]
- [[Dolly]]
- [[RWKV]]
- [[Codex]]
- [[Minerva]]
- [[WebGPT]]
- [[Toolformer]]
- [[Gorilla]]
- [[GPT-J]]
- [[GPT-NeoX]]
- [[Gopher]]
- [[AlphaCode]]
- [[AlphaGeometry]]
- [[MPT]] (Mosaic Pretrained Transformers)
- [[OLMo]] (Open Language Model)
- [[Zephyr]]
- [[Orca]]
- [[Orca 2]]
- [[LIMA]]
- [[DBRX]]
- [[SimCLR]]
- [[SimCLR v2]]
- [[SimVLM]]
- [[BYOL]]
- [[ULMFiT]]
- [[StarCoder]]
- [[StarCoder 2]]
- [[WizardLM]]
- [[WizardLM 2]]
- [[WizardCoder]]
- [[WaveCoder]]
- [[Magicoder]]
- [[Starling]]
- [[SteerLM]]
- [[Jurassic-1]]
- [[LaMDA]]
- [[Pile-T5]]
- [[Guanaco]]
- [[JetMoE]]
- [[Command R]]
- [[Command R+]]
- [[Genstruct]]
- [[Rho-1]]
- [[Qwen]]
- [[Qwen 2]]
- [[Tulu]]
- [[Tulu 2]]
- [[Hermes]]
- [[Capybara]]
- [[DeepSeek-Coder]]
- [[DeepSeek-Math]]
- [[Ada-Instruct]]
- [[Yi]]
- [[ALIGN]]
- [[GLIDE]]
- [[ImageBind]]
- [[Imagen]]
- [[Contrastive Captioner]] (CoCa)
- [[OpenChat]]
- [[LaMini-LM]]
- [[Longform]]
- [[Humpback]]
- [[OpenELM]]
- [[Medusa]]
- [[CogVLM]]
- [[LLaVA]]
- [[MemGPT]]
- [[FActScore]]
- [[Alpagasus]]
- [[Nemotron-4]]
- [[Shepherd]]
- [[Prometheus]]
- [[Prometheus 2]]

# Tools
- [[ComfyUI]] ğŸ‘¨â€ğŸ”¬ğŸ–¼ï¸
- [[Automatic1111]] ğŸ‘¨â€ğŸ”¬ğŸ–¼ï¸
- [[Axolotl]] ğŸ‘¨â€ğŸ”¬âš—ï¸
- [[Unsloth]] ğŸ‘¨â€ğŸ”¬âš—ï¸
- [[Oogabooga]] ğŸ‘¨â€ğŸ”¬âš—ï¸
- [[Gradio]] âš’ï¸âš¡
- [[Streamlit]] âš’ï¸âš¡
- [[MergeKit]] ğŸ™‚+ğŸ¤ 
- [[PIL]] (Python Image Library) ğŸ–¼ï¸
- [[GGML]] File format ğŸ’¿
- [[GGUF]] File Format ğŸ’¿
- [[GPTQ]] ğŸœ
- [[NF4]] (Normal Float 4-Bit) ğŸœ
- [[Ludwig]]
-  [[Eleuther LM Evaluation Harness]]
- [[LoRAX]] âš¡ğŸ¤–
- [[vLLM]]
- [[Datatrove]] ğŸ”ğŸ“
- [[Lighteval]] âš¡ğŸ”¬
- [[ChatML]]
- [[Airoboros]] ğŸ¤–ğŸ’½
- [[Instructor]] ğŸ‘®â€â™‚ï¸ğŸ¤–
- [[Outlines]] ğŸ‘®â€â™‚ï¸ğŸ¤–
- [[Argilla]]
- [[Distilabel]] ğŸ¤–ğŸ’½
- [[LabelStudio]]
- [[CleanLab]]
- [[AlpacaFarm]]
- [[TRL]] (Transformer Reinforcement Learning)
- [[ONNX]] (Open Neural Network Exchange)
- [[Safetensors]]
- [[llama.cpp]]
- [[Llamafile]]
- [[fastText]]
- [[Trafilatura]] ğŸ”ğŸ“
- [[Langtrace]] (Unsure if this should be here.)
- [[LangChain]] ğŸ—£ï¸â›“ï¸
- [[LangSmith]] ğŸ—£ï¸ğŸ”¬
- [[Modal]] ğŸŸ©ğŸ¤–
- [[RAGAS]] ğŸ“ğŸ”¬
- [[Sentence Transformers]] ğŸ“Š
- [[Weave]] ğŸ—£ï¸ğŸ”¬
- [[Natural Language Toolkit]] (NLTK) ğŸ§°ğŸ› ï¸
- [[spaCy]] ğŸª™ğŸ§¨
- [[HuggingFace Tokenizers]] ğŸª™ğŸ¤—
- [[EvalGen]] ğŸ§ª
-  [[Zeta Alpha]] ğŸ“
- [[Weights and Biases]] ğŸ“Š
- [[Replicate]] ğŸš‚
- [[bitsandbytes]] ğŸœ

# Benchmarks, Evaluations
*These are oftentimes also dataset, but they're not generally datasets that you should train/finetune models on*
- [[GAIA]] (General AI Assistants benchmark)
- [[Massive Multi-Task Language Understanding]] (MMLU)
- [[MMLU-Pro]]
- [[MMLU-Redux]]
- [[HumanEval]]
- [[BIG-Bench]] (Beyond the Imitation Game Benchmark)
- [[BIG-Bench Hard]]
- [[BIG-Bench Lite]]
- [[BigCodeBench]]
- [[SWE-bench]]
- [[DAWNBench]]
- [[HELM]] (Holistic Evaluation of Language Models)
- [[GLUE]] (General Language Understanding Evaluation)
- [[SuperGLUE]]
- [[SWAG]] (Situations with Adversarial Generations)
- [[HellaSWAG]]
- [[MNLI]] (Multi-Genre Natural Language Inference)
- [[Paloma]]
- [[BEIR]] (Benchmarking IR)
- [[GPQA]] (Google-Proof Q&A Benchmark)
- [[GSM8K]] (Grade School Math)
- [[VQAv2]] (Visual Question Answering)
- [[Massive Multi-Discipline Multimodal Understanding]] (Massive Multi-discipline Multimodal Understanding)
- [[HotpotQA]]
- [[HoVer]]
- [[SQuAD]] (Stanford Question Answering Dataset)
- [[ChatBotArena]]
- [[OpenLLM Leaderboard]]
- [[MT-Bench]] (Multi-Turn Benchmark)
- [[AlpacaEval]]
- [[AGIEval]]
- [[Winograd]]  (Winograd schemas)
- [[Winogrande]]
- [[Winoground]]
- [[Dynabench]]
- [[Dynaboard]]
- [[RewardBench]]
- [[MTEB]] (Massive Text Embedding Benchmark)
- [[Massive Multi-Discipline Multimodal Understanding]] (MMMU)
- [[MMBench]]
- [[Open VLM Leaderboard]]
- [[LAMBADA]]
- [[RACE]]
- [[Berkeley Function-Calling Leaderboard]]
- [[IFEval]]

# Datasets
*Datasets for training/finetuning models*
- [[Common Crawl]]
- [[C4]] (Colossal, Cleaned Common Crawl)
- [[Webtext]]
- [[The Stack]]
- [[The Stack v2]]
- [[ShareGPT]]
- [[The Pile]]
- [[CIFAR-10]] (Canadian Institute for Advanced Research)
- [[MNIST]] (Modified National Institute of Standards and Technology)
- [[LAION-400M]] (Large-scale Artificial Intelligence Open Network)
- [[LAION-5B]]
- [[MMC4]] (Multimodal C4)
- [[MS MARCO]] (Microsoft Machine Reading Comprehension)
- [[MS MARCO Web Search]]
- [[ClueWeb22]]
- [[RedPajama]]
- [[SlimPajama]]
- [[RedPajama v2]]
- [[Project Gutenberg]]
- [[MassiveText]] (Includes interesting work on quality/repetition filters)
- [[UltraChat]]
- [[UltraFeedback]]
- [[UltraInteract]]
- [[Dolma]] (Dataset for OLMo)
- [[RefinedWeb]] (Dataset for Falcon)
- [[Cosmopedia]] (Large 25B token synthetic dataset from HF)
- [[FineWeb]] (15T high-quality dataset from HF)
- [[FineWeb-Edu]] (A very high-quality filtered subset)
- [[oasst1]]
- [[oasst2]]
- [[Stanford Natural Language Inference]] (SNLI)
- [[Multi-Genre NLI]] (MNLI)
- [[Stanford Human Preferences]] (SHP)
- [[Helpful and Harmless]] (HH)
- [[TL;DR]]
- [[Nectar]]
- [[Tulu-v2-sft-mixture]]
- [[S2ORC]] (Semantic Scholar Open Research Corpus)
- [[Natural Instructions]]
- [[Super-NaturalInstructions]]
- [[Unnatural Instructions]]
- [[OpenHermes Dataset]]
- [[OpenHermes2.5 Dataset]]
- [[FLAN v2]]
- [[OpenOrca Dataset]]
- [[SlimOrca]]
- [[Common Objects in Context]]
- [[LoTTE]] (Long-Tail Topic-stratified Evaluation)
- [[Natural Questions]]
- [[Feedback Collection]]
- [[Preference Collection]]
- [[Capybara Dataset]]
- [[CCNet]] (Cluster-Coordinated Net)
- [[DataComp]]
- [[DataComp-LM]]

# Entities
- [[Cohere]]  ğŸ“
- [[CharacterAI]]  ğŸ’â€â™€ï¸
- [[TogetherAI]]  ğŸ¤
- [[OpenAI]]  ğŸ‘º
- [[Anthropic]]  ğŸ‘¨
- [[Google Research]]  ğŸ§ 
- [[HuggingFace]] ğŸ¤—
- [[Inflection]] â˜ ï¸
- [[DeepMind]]  ğŸ§ 
- [[Allen Institute]] (AI2)  ğŸ“
- [[AI21]]  ğŸ‡®ğŸ‡±
- [[Microsoft Research]] (MSR)  ğŸŒ²
- [[Stanford AI Lab]] (SAIL)  â›µï¸
- [[Berkeley AI Research Lab]] (BAIR)  ğŸ»
- [[Snorkel AI]]  ğŸ¤¿
- [[Meta AI Research]] (FAIR)  ğŸ§‘â€ğŸ’»
- [[Mistral]]  ğŸ‡«ğŸ‡·
- [[Nvidia]]  ğŸ’°
- [[Center for Research on Foundation Models]] (CRFM)  ğŸ”¬
- [[Alignment Research Center]] (ARC)  ğŸ™€
- [[Model Evaluation and Threat Research]] (METR) â—
- [[Machine Intelligence Research Institute]] (MIRI)  ğŸ”¥
- [[Stanford Institute for Human-Centered Artificial Intelligence]] (HAI)  ğŸ¤–
- [[MosaicML]]  ğŸŒ­
- [[IBM]] ğŸ¤¡
- [[DataBricks]]  ğŸ§±
- [[Nous Research]] ğŸ› ï¸
- [[KAIST|Korea Advanced Institute of Science & Technology]] (KAIST) ğŸ‡°ğŸ‡·
- [[Adept]]  ğŸ•µï¸
- [[Contextual]]  ğŸ“
- [[Reka AI]]  â“
- [[Alibaba Research]]  ğŸ‡¨ğŸ‡³ğŸ’°
- [[DeepSeek]] ğŸ‡¨ğŸ‡³ğŸ§‘â€ğŸ’»
- [[01.AI]]  ğŸ‡¨ğŸ‡³
- [[LAION]]  ğŸ’½
- [[National Institute of Standards and Technology]] (NIST)  ğŸ‘®â€â™‚ï¸
- [[Cerebras]]  ğŸŸ§
- [[LMSYS]] âš”ï¸
- [[Salesforce Research]]  ğŸ’¼
- [[Apple]] ï£¿
- [[EssentialAI]] ğŸ˜¶
- [[Groq]] ğŸï¸
- [[Safe SuperIntelligence]] (SSI) âš—ï¸


# People
- [[Noam Shazeer]]  ğŸ§
- [[Nathan Lambert]]  âš—ï¸
- [[Daphne Koeller]] ğŸ‘©
- [[Melanie Mitchell]] ğŸ‘©
- [[Percy Liang]] ğŸ§
- [[Ilya Sutskever]] ğŸ«¥
- [[Greg Brockman]] ğŸ—¿
- [[Sam Altman]] ğŸ‘¹
- [[Clem Delangue]] ğŸ¤—
- [[Mustafa Suleyman]] ğŸ¤¡
- [[Demis Hassabis]] â™Ÿï¸
- [[Geoff Hinton]] ğŸ‘¨â€ğŸ¦³
- [[Fei-Fei Li]] ğŸ¥°
- [[Yann LeCun]] ğŸ‡¨ğŸ‡¦
- [[Jeremy Howard]] ğŸ‘¨â€ğŸ”¬
- [[Andrej Karpathy]] ğŸ
- [[Andrew Ng]] ğŸ¤´
- [[Yoshua Bengio]] ğŸ™€
- [[Samy Bengio]] ğŸ§Œ
- [[Jurgen Schmidhuber]] â˜ï¸
- [[Stuart Russell]] ğŸ‘¨â€ğŸ¦³
- [[Peter Norvig]] ğŸ‘¨â€ğŸ¦³
- [[Richard Sutton]] ğŸ‘¨â€ğŸ¦³
- [[Pieter Abbeel]] ğŸ¤–
- [[Yejin Choi]] ğŸ¿
- [[Paul Christiano]] ğŸš¨
- [[Ludwig Schmidt]] ğŸ˜
- [[Chris RÃ©]] ğŸ§ 
- [[Alex Ratner]] ğŸ¤¿
- [[Sasha Rush]] ğŸ‘¨â€ğŸ«
- [[Jonathan Frankle]] ğŸŒ­
- [[Sara Hooker]] ğŸª
- [[Ishan Misra]] ğŸ‘ï¸
- [[Sebastian Ruder]] ğŸ§‘â€ğŸ«
- [[Douwe Kiela]] ğŸ“
- [[Alec Radford]] ğŸ
- [[Christopher Potts]] ğŸ§‘â€ğŸ«
- [[Yi Tay]] ğŸ‘¨â€ğŸ”¬
- [[Maxime Labonne]] ğŸ‘¨â€ğŸ”¬
- [[Jon Durbin]] ğŸ‘¨â€ğŸ”¬
- [[Jared Kaplan]] âš›ï¸
- [[Arthur Mensch]] ğŸ‡«ğŸ‡·
- [[Quoc Le]] ğŸ
- [[Tri Dao]] ğŸŒ½
- [[Tim Dettmers]] ğŸ¤
- [[Dario Amodei]] âš›ï¸
- [[Alex Krizhevsky]] ğŸ
- [[Nils Reimers]] ğŸ‘¨â€ğŸ”¬
- [[Omar Khattab]] ğŸ“‚
- [[John Schulman]] ğŸ¤–
- [[Noam Chomsky]] ğŸ—£ï¸
- [[Jeff Dean]] ğŸ
- [[Jack Clark]] ğŸ“
- [[Matei Zaharia]] ğŸ§±
- [[Shreya Shankar]] ğŸ“Š
- [[Charles Frye]] ğŸŸ©
- [[Georgei Gerganov]] ğŸ“¦
- [[Benjamin ClaviÃ©]] ğŸ‡«ğŸ‡·ğŸ