Initial training of a language model, most commonly using a self-supervised autoregressive language modeling objective of next-token-prediction.

The self-supervised nature allows "easy" scaling to large corpuses of (pre-filtered) web documents.