August 2021 -- [[AI21]] (1 year after [[GPT-3]], 3 months before ChatGPT)
Paper: [Jurassic 1: Technical Details and Evaluation](https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf)

A 7B and 178B parameter model from an Israeli lab.
Performed well for the size, not as good as GPT-3 though. In the "reimplement GPT-3" rush era.

Abstract
> Jurassic-1 is a pair of auto-regressive language models recently released by AI21 Labs, consisting of J1-Jumbo, a 178B-parameter model, and J1-Large, a 7B-parameter model. We describe their architecture and training, and evaluate their performance relative to GPT-3. The evaluation is in terms of perplexity, as well as zero-shot and few-shot learning. To that end, we developed a zeroshot and few-shot test suite, which we made publicly available (https://github.com/ai21labs/ lm-evaluation) as a shared resource for the evaluation of mega language models

![[Pasted image 20240419003444.png]]