---
aliases:
  - CoN
---
November 15, 2023
Tencent AI
Paper: [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](https://arxiv.org/abs/2311.09210)
#zotero 
Takeaway: A technique aimed at improving the robustness of retrieval-augmented language models when being fed noisy, irrelevant documents, and in handling unknown scenarios. CoN generates sequential reading notes for retrieved documents, enabling a thorough evaluation of their relevance to the given question, and integrating this information to formulate the final answer.
Sort of a boring paper -- basically just asking the LM to sequentially summarize retrieved documents before making a decision.

---

Notes:
- Chain-of-Note aims to improve the robustness of retrieval-augmented language models (RALMs), focusing on two pivotal aspects:
	1. Noise Robustness: The ability of a RALM to discern and disregard noisy information present in irrelevant retrieved documents, while approximately leveraging its intrinsic knowledge.
	2. Unknown Robustness: The capacity of a RALM to acknowledge its limitations, and respond with an "unknown" response when given a query that it has neither the **intrinsic**/parametric nor **extrinsic** (retrieved) knowledge to answer.
- The cornerstone of ==Chain of Noting== is to generate a series of reading notes for retrieved documents, enabling a comprehensive assessment of their relevance to the input query.
	- This evaluates the document's pertinence while also pinpointing the most critical and reliable information therein, filtering out irrelevant or less-credible content, leading to responses that are more precise and contextually-relevant.
	- In cases where retrieved documents do not provide any relevant information CoN can guide the model to acknowledge its limitations and respond with an "unknown," or provide the best possible explanation based on available data.
- Notes current challenges of existing RALMs:
	1. **Risk of Surface-Level Processing**: When generating an answer, LMs might rely on surface-level information without deep comprehension, overlooking details of the question or documents.
	2. **Difficulty in Handling Contradictory Information**: When documents contain contradictory information, determining truth is challenging.
	3. **Reduced Transparency and Interpretability**: *Directly generating an answer* (even document-aided) provides limited insight into how the model arrived at its conclusions.
	4. **Over-dependence on Retrieved Documents**: Direct generation can lead to an over-reliance on the content of retrieved documents, ignoring the model's inherent knowledge base, even when retrieved documents are noisy or out-of-date.
- To equip the model with the ability to generate reading notes, we gather appropriate training data generated by ChatGPT. This is both cost-effective and enhances reproducibility. We initiate this process by randomly sampling 10k questions from the [[Natural Questions]] dataset, and prompt ChatGPT with specific instructions and hand-written in-context examples for each of the three types of note generation (see Figure 2). After collecting these 10k training datas, we train our CoN model based on [[LLaMA 2]] 7B by concatenating the question and documents as the prompt, and training the model to generate notes and answers in a standard, supervised way.
	- One change is that they use a "weighted loss strategy," involving varying the loss weights associated with the reading notes and the answers. Equal weighting of both components results in worse quality and longer convergence. Instead, 50% of the time, the NTP loss is computed on the *entire notes and answer sequence*, and 50% of the time, the NTP loss is computed only on the answer. We want to ensure the model learns to generate rich reading notes, but the primary focus is on the accuracy/reliability of the final answer.


# Paper Figures
![[Pasted image 20240506143723.png]]
![[Pasted image 20240506150931.png]]

![[Pasted image 20240506152911.png]]

![[Pasted image 20240506152932.png]]

