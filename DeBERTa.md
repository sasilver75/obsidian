---
aliases:
  - Decoding-enhanced BERT with Disentangled Attention
---


June 5, 2020
[[Microsoft Research]]
[DeBERTa: Decoding-Enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654)

Separate representations for word and positions, with distinct attention connections. Decouples word and position by decoupling representations, and having distinct attention mechanisms to each part.



# Non-Paper Figures
![[Pasted image 20240619172743.png]]