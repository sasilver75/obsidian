![[Pasted image 20231215171803.png|300]]
![[Pasted image 20231224000029.png|300]]![[Pasted image 20231224001343.png|300]]

![[Pasted image 20231224001556.png|300]]![[Pasted image 20231224003503.png|300]]
![[Pasted image 20231224003841.png|300]]
![[Pasted image 20231224131650.png|300]]
![[Pasted image 20231224132027.png|300]]
![[Pasted image 20231224132852.png|300]]
![[Pasted image 20231224135822.png|300]]
![[Pasted image 20231224135808.png|300]]![[Pasted image 20231224135911.png|300]]
![[Pasted image 20231224140449.png|300]]


![[Pasted image 20231224155343.png|300]]![[Pasted image 20231224160119.png]

![[Pasted image 20231224160249.png|300]]

![[Pasted image 20231224160322.png|300]]
(Rotations work very well and produce strong features, despite being simple!)

![[Pasted image 20231224160618.png|300]]![[Pasted image 20231224171000.png|300]]
![[Pasted image 20231224171628.png|300]]

![[Pasted image 20240122211056.png|300]]
![[Pasted image 20240124184241.png|300]]

![[Pasted image 20240124184228.png|300]]

Byte Magazine Covers - https://lunduke.substack.com/p/the-truly-epic-byte-magazine-covers

![[Pasted image 20240127145004.png|300]]
(From Youtube: https://youtu.be/c_jjyIJ4ci8?si=KVWMwUiQnPPxx868)

![[Pasted image 20240129161437.png|300]]
(From Youtube: https://youtu.be/X-82uXrw76s?si=QRWRNj2E8scJYfP4)

![[Pasted image 20240129230748.png|300]]
(From Yannic Kilchner Discord; An example of bots: https://discord.com/channels/714501525455634453/834836108000886805/1200085021705388062)
![[Pasted image 20240129230809.png|300]]
(From Yannic Kilchner Discord; An example of bots: https://discord.com/channels/714501525455634453/834836108000886805/1200085021705388062)


![[Pasted image 20240131205312.png|300]]
From: https://www.youtube.com/watch?v=KCXDr-UOb9A

![[Pasted image 20240201111336.png|300]]
From: https://youtu.be/BN6tTdWcIcQ?si=9S3FG70jYseBcPqj

![[Pasted image 20240131144136.png|300]]
From SnorkelAI Andrew Ng

![[Pasted image 20240205172048.png|300]]![[Pasted image 20240208123653.png|300]]
![[Pasted image 20240210020210.png|300]]
From: https://news.ycombinator.com/item?id=33831759 

![[Pasted image 20240211134130.png|300]]
From: https://www.youtube.com/watch?v=6lVBp2XjWsg

![[Pasted image 20240214111538.png|300]]

![[Pasted image 20240214123110.png|300]]
Re: Length bias in LLM-as a judge in AlpacaEval (Feb 14, 23)

![[Pasted image 20240214124305.png|300]]
From Latent Space Paper Club chat (LeveragingLarge Language Models for NLG Evaluation: A Survey) "I don't know how they got to that number, it's just what they provided to me."
![[Pasted image 20240218172236.png|300]]
![[Pasted image 20240219131023.png|300]]

![[Pasted image 20240220132410.png|300]]
As an example of how easy it is to get around guardrails (usecase: copywrite)

![[Pasted image 20240221205508.png|300]]
From XKCD; Re: evaluation of language model next-token-prediction

![[Pasted image 20240222114053.png|300]]
Above: The "pro-diversity" guardrails seemed to work for the {Profession} case, but not for the {Profession1 and Profession2} case. This is from DALLE-3, but the same thing was observed in Gemeni in Feb 2024, when there was a hullabaloo about Gemeni creating black Nazi soldiers, etc.

![[Pasted image 20240222121537.png|300]]
Yud on Safety, Feb 22, after the Google Gemeni kerfuffle with the black Nazis, etc.

![[Pasted image 20240222134504.png|300]]
From Emmett Shear on Twitter

![[Pasted image 20240222145858.png|300]]
Torment Nexus meme

![[Pasted image 20240222152053.png|300]]

![[Pasted image 20240222155809.png|300]]
The Chinese Room Experiment

![[Pasted image 20240228101951.png|300]]
Feb 2024 OpenAI protest

![[Pasted image 20240228143011.png|300]]

![[Pasted image 20240309191916.png|300]]
![[Pasted image 20240311192314.png|300]]

![[Pasted image 20240311192323.png|300]]

![[Pasted image 20240311192422.png|300]]

![[Pasted image 20240311193133.png|300]]
![[Pasted image 20240327010754.png|300|300]]
![[Pasted image 20240327012519.png|200|300]]

![[Pasted image 20240330002147.png|400|300]]

![[Pasted image 20240330005607.png|400|300]]

![[Pasted image 20240330010736.png|400|300]]![[Pasted image 20240331232918.png|300]]
Above: context being explaining word2vec; "You shall know a word by the company it keeps" is a good reference

![[Pasted image 20240401142942.png|300]]
Different uses of the word "pike": re: how embeddings should be contextual

![[Pasted image 20240403175421.png|300]]
![[Pasted image 20240403175714.png|300]]
(From: https://youtu.be/5q0GN2M1d2c?si=uAqMOuUqf7PsytY7)
![[Pasted image 20240403200819.png|450|300]]
![[Pasted image 20240403212659.png|300]]
![[Pasted image 20240403221104.png|300]]
![[Pasted image 20240403225624.png|300]]
Above: Showing that the simple addition of CoT pushed model performance above the human average.


![[Pasted image 20240404161038.png|300]]
![[Pasted image 20240404161005.png|300]]
Questions re: RAG

![[Pasted image 20240404201323.png|300]]

![[Pasted image 20240405013204.png|300]]
![[Pasted image 20240405021834.png|300]]
![[Pasted image 20240408171501.png|300]]
Above: Great explanation of the vanilla LSTM from CS224N Lecture 6

![[Pasted image 20240408171933.png|300]]


![[Pasted image 20240410184710.png|300]]
On what types of knowledge Pretraining teaches

![[Pasted image 20240410221505.png|300]]
On the impact on Instruction-Tuning, versus a raw pretrained model
![[Pasted image 20240411110714.png|300]]
Sort of why using LLMs as a general computing OS doesn't always make sense.

![[Pasted image 20240411202109.png|300]]

There are still problems with LLMs
- Jailbreaks
- Hallucinations/Factual errors
- Text generation models are often constructed from pretrained LMs trained on internet data containing harmful stuff and bias.
	- Adversarial inputs can trigger VERY toxic content!
	- Even if you don't try to trigger the model, using very innocuous prompts, it can start generating toxic content by itself!

Models shouldn't be deployed without proper safeguards, and without understanding about how users will interact with models.

![[Pasted image 20240411202557.png|300]]

![[Pasted image 20240413231628.png|300]]
![[Pasted image 20240413231630.png|300]]
![[Pasted image 20240415152438.png|300]]
![[Pasted image 20240415154601.png|300]]
From the Yi paper: https://arxiv.org/html/2403.04652v1
![[Pasted image 20240415155657.png|300]]
![[Pasted image 20240415155715.png|300]]
From Falcon's RefineWeb dataset; Showing how much of the initial data we end up actually removing throughout a pipeline similar to the one shown in the Yi image above. So if you want to end up with (eg) 1T tokens, you have to start with a very large source(s).
![[Pasted image 20240415155849.png|300]]
From the AllenAI Dataset survey paper, showing a very similar workflow to the previous ones
![[Pasted image 20240415160930.png|300]]
([ThomWolf](https://youtu.be/2-SPH9hIKT8?si=n4JiXW9ooiOJ4Wrf)) An example of heuristics that are used (eg in FastText) to filter poor-quality documents. 
- Advantages of heuristics: Controlled, robust, rather clear priors
- Drawbacks of heuristics: Rely entirely on surface level; might remove too much; hyper-parameter tuning can be time consuming and onerous
Alternatively, you could use a ML classifier (eg) or use perplexity-based filtering 
- fastText classification with some N Grams, labeling them good or bad
- 5-gram Kneser-Ney model on Wikipedia
Though this may introduce unwanted "bias" - Wikipedia is written 90% by men. By preferring the "high-quality" of Wikipedia, you might be biasing your data in ways that *may* not be desirable.
Additional notes: 
- Take care of domain specifics! Examine the effect of filters/transforms on domain-specific data - you might need domain-specific hyperparameters/heuristics
- Manually sample ad inspect your data post transforming!
- Deduplicate:
	- Fuzzy: (HF uses many of these)
		- [[Bloom Filter|300]]: Hashing and fixed-size vector 
		- [[MinHash|300]]: Hashing and sorting
	- Exact (very costly in memory):
		- Exact substring with suffix-array
		- Sentence-level deduplication
- Counter-intuitive result: Deduplication resulted in them removing (copies of) much of the *good* data, leaving them with a higher proportion of "bad" data! Oops!
![[Pasted image 20240415162732.png|300]]
How do you evaluate data quality in a 1T+ corpus?
- Train a small (1B,2B under Chinchilla optimality)
- Use a set of "high signal benchmarks" (smoothly improving performance with low variance)
	- CommonSense QA, [[HellaSWAG|300]], Openbook QA, PiQA, SIQA, [[Winogrande|300]], [[Abstraction and Reasoning Corpus|ARC|300]], [[Massive Multi-Task Language Understanding|MMLU|300]]
- Use a debugging dataset so that you can tell your datasets apart (2 -- one of high quality (C4), and one that's more complex)
![[Pasted image 20240415162904.png|300]]
`datatrove` is a library that HuggingFace+friends released to help process and filter data, and basically for preparing very large datasets for LLM training. It's fully in Python and very easy to set up on SLURM locally, to use remote filesystems as well, if you want to.
`lighteval` is a lightweight LLM evaluation suite inspired by the Eleuther Test Harness! 
![[Pasted image 20240415163527.png|300]]
[[Data Parallelism|300]]: Usually works out-of-the-box; the easier one. You take a model, duplicating it over several GPU; you feed different cores several different parts of your batch, you merge/reduce the gradients from each of these sub-batches... so it's as if you had a larger batch across multiple GPUs. The all-reduce to merge the gradients can start to become a huge bottleneck.
[[Tensor Parallelism|300]]: Maybe your model is too big to be trained on a single GPU... You need to rewrite our model code; you divide all the matrices we use in our model into four or eight, and put each part of the submatrices on each GPU, and synchronization happens after the operation.
[[Pipeline Parallelism|300]]: Put some layers on some GPU, other layers on other GPUs; communicate at the interface of these layers.
[[Sequence Parallelism|300]]: (Careful with the name, there's one definition of this that's related to [[RingAttention|300]]). It's in some way similar to Tensor Parallelism, but instead of slicing the parameter matrices, we slice the sequences. Usually only interesting during training.

![[Pasted image 20240417002314.png|300]]
From CS224NL16(2023): Many different ways to do fusion of modalities, and much literature arguing in various ways.

![[Pasted image 20240417002349.png|300]]
1. Combine modalities at beginning ("Early fusion")
2. Treat them separately and then later combine them ("Middle fusion")
3. Combine just the scores/logits ("Late fusion")
	- This is what we would now call contrastive models

![[Pasted image 20240417130630.png|300|300]]
![[Pasted image 20240417130642.png|300|300]]

![[Pasted image 20240417161847.png|300|300]]
![[Pasted image 20240417163859.png|300|300]]
![[Pasted image 20240418163127.png|300]]
(From Nathan Lambert's CS25 talk)
![[Pasted image 20240418164208.png|300]]
(From Nathan Lambert's CS25 talk)
![[Pasted image 20240418170217.png|300]]
(From Nathan Lambert's CS25 talk)
![[Pasted image 20240418172936.png|300]]
(From Nathan Lambert's CS25 talk)
![[Pasted image 20240418173227.png|300]]
(From Nathan Lambert's CS25 talk)
![[Pasted image 20240419151848.png|300]]
Classic prompt engineering
![[Pasted image 20240422115127.png|300]]
![[Pasted image 20240423001142.png|300|300]]
From a near post: https://twitter.com/nearcyan/status/1782617805827031217 It sucks
![[Pasted image 20240423003237.png|300]]
From a near Post; This is TruthfulQA https://x.com/nearcyan/status/1782625091156922482 It sucks

![[Pasted image 20240424010636.png|300]]
A timeline of public Instruction-Tuning datasets, up to FLAN 2022
![[Pasted image 20240424144735.png|300]]
More on Context making static representations of words a silly goal, from CS224U, L2

![[Pasted image 20240426121952.png|300]]
![[Pasted image 20240426130927.png|300]]

![[Pasted image 20240504123138.png|300]]
Interesting that perhaps [[L1 Regularization]] isn't that good for DNN?

![[Pasted image 20240509002950.png|250]]
A table of 40 hallucination-inducing questions from the [[LaMini-LM]] paper.

![[Pasted image 20240510233232.png]]
Above: Some funny prompts that have been used on ChatBotArena

![[Pasted image 20240516223002.png|300]]
Above: Comparison of ==Pairwise Ranking== and ==Direct Assessment== tasks for LM evaluators

![[Pasted image 20240520183827.png]]

![[Pasted image 20240520183905.png]]

![[Pasted image 20240522194541.png]]

![[Pasted image 20240523120834.png]]
![[Pasted image 20240523160226.png]]
Above: Google using AI results on their search queries making people angry.

![[Pasted image 20240528225721.png|300]]
Showing [[Top-P Sampling|Nucleus Sampling]], [[Top-K Sampling]], [[Beam Search]], from the "Curious Case of Neural Text Degeneration" (2020) paper

![[Pasted image 20240604111759.png|300]]
Above: Response to Dwarkesh's episode with Leopold Aschenbrenner


