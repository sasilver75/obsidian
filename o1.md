September 12, 2024
[[OpenAI]]
Blog post: [Introducing OpenAI o1](https://openai.com/o1/)
- Product post: [Introducing Open AI o1-preview](https://openai.com/index/introducing-openai-o1-preview/)
- Eng post: [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/)
	- This one has a great set of examples of the thought process

References:
- Sequoia: [OpenAI's Noam Brown, Ilge Akkaya and Hunter Lightman on o1 and Teaching LLMs to Reason Better](https://youtu.be/jPluSXJpdrA?si=cdGuAYyW679EQfpa)
- [A wet blanket: Subbarao Kambhampati analyzing o1 performance, and comparing o1 to 4o-mini with an LLM-modulo framework](https://x.com/rao2z/status/1843307760311533768)

Models:
- o1-preview
- o1-mini (80% cheaper than preview, competitive with it on coding tasks)

>  In a qualifying exam for the International Mathematics Olympiad (IMO), ==GPT-4o correctly solved only 13% of problems, while the reasoning model scored 83%.==

> As part of developing these new models, we have come up with a new safety training approach that ==harnesses their reasoning capabilities to make them adhere to safety and alignment guidelines==. By being able to reason about our safety rules in context, it can apply them more effectively. On one of our hardest jailbreaking tests, ==GPT-4o scored 22 (on a scale of 0-100) while our o1-preview model scored 84==. You can read more about this in the [system card](https://openai.com/index/openai-o1-system-card/) and our [research post](https://openai.com/index/learning-to-reason-with-llms/).

![[Pasted image 20241008101825.png|500]]


![[Pasted image 20241008102016.png|400]]

![[Pasted image 20241008102035.png|500]]



