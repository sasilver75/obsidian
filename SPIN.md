---
aliases:
  - Self-Play Fine-Tuning
---
January 2, 2024
UCLA
Paper: [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/abs/2401.01335)
#zotero 
Takeaway: A method of fine-tuning a base LM and improving it to human-level performance. SPIN allows the LLM to engage in self-play, eliminating the need for an expert annotator. The gist of the self-play is that an LLM from the previous iteration generates responses to prompts in a human-annotated SFT dataset. We then try to find a new LLM capable of distinguishing between the responses generated by the LM and the responses generated by humans. We then repeat this process. ((Sort of resembles the GAN process, but using only one model))

----

Notes:
- SPIN Algorithm
	- Begins from a supervised fine-tuned model. SPIN allows the LLM to engage in self-play, eliminating, the need for an expert annotator such as a human, or more advanced LLMs like GPT-4.
	- In detail, with the LLM from previous iteration is employed to generate responses to the prompts in the human annotated SFT dataset.
	- The subsequent objective is to find a new LLM capable of distinguishing between the responses generated by the model and the responses generated by humans.
	- This process can be seen as a two player game where the main player (the new LLM) seeks to discern between the responses of the opponent player (the old LLM) and human-generated responses, while the opponent (old LLM) seems to generate responses as similar as possible to those in the human-annotated SFT dataset.
	- The new LLM is obtained by fine-tuning the old one to prefer responses from the human distribution, rather than the model distribution.
	- In the next iteration, the newly-obtained LLM becomes the opponent for response generation, with the self-play process aiming for the LLM distribution to eventually converge to the human distribution, with indistinguishable responses from human ones.
- 

((I think I saw people on Twitter saying that this didn't really seem to reproduce, unfortunately))


# Paper Figures

![[Pasted image 20240506202526.png]]

![[Pasted image 20240506203015.png]]
![[Pasted image 20240506203303.png]]