{
  "recentFiles": [
    {
      "basename": "SmolLM",
      "path": "SmolLM.md"
    },
    {
      "basename": "StarCoder",
      "path": "StarCoder.md"
    },
    {
      "basename": "~ Ideas",
      "path": "~ Ideas.md"
    },
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning",
      "path": "Papers/General/Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning.md"
    },
    {
      "basename": "Cosmopedia",
      "path": "Cosmopedia.md"
    },
    {
      "basename": "Phi-2",
      "path": "Phi-2.md"
    },
    {
      "basename": "Phi-3",
      "path": "Phi-3.md"
    },
    {
      "basename": "FLAMe",
      "path": "FLAMe.md"
    },
    {
      "basename": "WizardMath",
      "path": "WizardMath.md"
    },
    {
      "basename": "Reward-Augmented Decoding",
      "path": "Reward-Augmented Decoding.md"
    },
    {
      "basename": "chrF",
      "path": "chrF.md"
    },
    {
      "basename": "Let's Verify Step by Step",
      "path": "Papers/General/Let's Verify Step by Step.md"
    },
    {
      "basename": "Quiet STaR",
      "path": "Quiet STaR.md"
    },
    {
      "basename": "Reinforced Self-Training",
      "path": "Reinforced Self-Training.md"
    },
    {
      "basename": "Self-Consistency",
      "path": "Self-Consistency.md"
    },
    {
      "basename": "Self-Taught Optimizer",
      "path": "Self-Taught Optimizer.md"
    },
    {
      "basename": "Eric Zelikman",
      "path": "Eric Zelikman.md"
    },
    {
      "basename": "GenQA",
      "path": "GenQA.md"
    },
    {
      "basename": "Constrained Decoding",
      "path": "Constrained Decoding.md"
    },
    {
      "basename": "Rejection Sampling",
      "path": "Rejection Sampling.md"
    },
    {
      "basename": "Scalable Oversight",
      "path": "Scalable Oversight.md"
    },
    {
      "basename": "Self-Taught Reasoner",
      "path": "Self-Taught Reasoner.md"
    },
    {
      "basename": "Reward Model",
      "path": "Reward Model.md"
    },
    {
      "basename": "Direct Preference Optimization",
      "path": "Direct Preference Optimization.md"
    },
    {
      "basename": "Zephyr",
      "path": "Zephyr.md"
    },
    {
      "basename": "AlpaGasus",
      "path": "AlpaGasus.md"
    },
    {
      "basename": "Nemotron-4",
      "path": "Nemotron-4.md"
    },
    {
      "basename": "AgentInstruct",
      "path": "AgentInstruct.md"
    },
    {
      "basename": "FLAN",
      "path": "FLAN.md"
    },
    {
      "basename": "Synthetic Data",
      "path": "Synthetic Data.md"
    },
    {
      "basename": "The RetroInstruct Guide to Synthetic Text Data (July 12, 2024) {John David Pressman}",
      "path": "Articles/The RetroInstruct Guide to Synthetic Text Data (July 12, 2024) {John David Pressman}.md"
    },
    {
      "basename": "Synthetic Data Index",
      "path": "Indices/Synthetic Data Index.md"
    },
    {
      "basename": "Web Rephrase Augmented Pre-training",
      "path": "Web Rephrase Augmented Pre-training.md"
    },
    {
      "basename": "Auto Evol-Instruct",
      "path": "Auto Evol-Instruct.md"
    },
    {
      "basename": "7 Tips for Junior Researchers (?) {Ofir Press}",
      "path": "Articles/7 Tips for Junior Researchers (?) {Ofir Press}.md"
    },
    {
      "basename": "~ Useful Pictures",
      "path": "~ Useful Pictures.md"
    },
    {
      "basename": "Chain of Thought",
      "path": "Chain of Thought.md"
    },
    {
      "basename": "Process Reward Model",
      "path": "Process Reward Model.md"
    },
    {
      "basename": "PRM800K",
      "path": "PRM800K.md"
    },
    {
      "basename": "AlpacaEval",
      "path": "AlpacaEval.md"
    },
    {
      "basename": "WizardCoder",
      "path": "WizardCoder.md"
    },
    {
      "basename": "Untitled 4",
      "path": "Untitled 4.md"
    },
    {
      "basename": "MT-Bench",
      "path": "MT-Bench.md"
    },
    {
      "basename": "Gemma 2",
      "path": "Gemma 2.md"
    },
    {
      "basename": "Solving math word problems with process- and outcome-based feedback",
      "path": "Papers/General/Solving math word problems with process- and outcome-based feedback.md"
    },
    {
      "basename": "Reward",
      "path": "Reward.md"
    },
    {
      "basename": "Why Reward Models are Key for Alignment (Feb 2024) {Nathan Lambert, Interconnects newsletter}",
      "path": "Articles/Why Reward Models are Key for Alignment (Feb 2024) {Nathan Lambert, Interconnects newsletter}.md"
    },
    {
      "basename": "The History of Open-Source LLMs - Imitation and Alignment (Part Three) (Aug 2023) {Cameron Wolfe, Deep Learning Focus Newsletter}",
      "path": "Articles/The History of Open-Source LLMs - Imitation and Alignment (Part Three) (Aug 2023) {Cameron Wolfe, Deep Learning Focus Newsletter}.md"
    },
    {
      "basename": "The History of Open-Source LLMs - Early Days (Part One) (Jul 2023) {Cameron Wolfe, PHD}",
      "path": "Articles/The History of Open-Source LLMs - Early Days (Part One) (Jul 2023) {Cameron Wolfe, PHD}.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}