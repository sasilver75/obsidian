{
  "recentFiles": [
    {
      "basename": "GLUE",
      "path": "GLUE.md"
    },
    {
      "basename": "SWAG",
      "path": "SWAG.md"
    },
    {
      "basename": "Winogrande",
      "path": "Winogrande.md"
    },
    {
      "basename": "Winograd",
      "path": "Winograd.md"
    },
    {
      "basename": "MNLI",
      "path": "MNLI.md"
    },
    {
      "basename": "Maximal Update Parameterization",
      "path": "Maximal Update Parameterization.md"
    },
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "~ Recommendations",
      "path": "~ Recommendations.md"
    },
    {
      "basename": "Recommendation Systems",
      "path": "Recommendation Systems.md"
    },
    {
      "basename": "Introduction to RL",
      "path": "Courses/Machine Learning/Spinning Up in RL/Introduction to RL.md"
    },
    {
      "basename": "Model Predictive Control",
      "path": "Model Predictive Control.md"
    },
    {
      "basename": "Lecture 5 Notes",
      "path": "Courses/Machine Learning/Deepmind x URL RL/Lecture 5 Notes.md"
    },
    {
      "basename": "Lecture 3 Notes",
      "path": "Courses/Machine Learning/Deepmind x URL RL/Lecture 3 Notes.md"
    },
    {
      "basename": "CS234 Lecture 3",
      "path": "Courses/Machine Learning/CS234/CS234 Lecture 3.md"
    },
    {
      "basename": "Lecture 3",
      "path": "Courses/UCSC/NLP201 NLP I/Lecture 3.md"
    },
    {
      "basename": "Logistic Regression",
      "path": "Logistic Regression.md"
    },
    {
      "basename": "Markov Assumption",
      "path": "Markov Assumption.md"
    },
    {
      "basename": "Markov Decision Process",
      "path": "Markov Decision Process.md"
    },
    {
      "basename": "Partially-Observable Markov Decision Process",
      "path": "Partially-Observable Markov Decision Process.md"
    },
    {
      "basename": "Policy Gradient",
      "path": "Policy Gradient.md"
    },
    {
      "basename": "Reinforcement Finetuning",
      "path": "Reinforcement Finetuning.md"
    },
    {
      "basename": "Reinforcement Learning from Verifiable Rewards",
      "path": "Reinforcement Learning from Verifiable Rewards.md"
    },
    {
      "basename": "~ Useful Pictures",
      "path": "~ Useful Pictures.md"
    },
    {
      "basename": "Untitled",
      "path": "Courses/Machine Learning/Untitled.md"
    },
    {
      "basename": "Regret",
      "path": "Regret.md"
    },
    {
      "basename": "Thompson Sampling",
      "path": "Thompson Sampling.md"
    },
    {
      "basename": "Bayesian Statistics",
      "path": "Bayesian Statistics.md"
    },
    {
      "basename": "Upper Confidence Bound",
      "path": "Upper Confidence Bound.md"
    },
    {
      "basename": "UPR",
      "path": "UPR.md"
    },
    {
      "basename": "CS234 Lecture 4",
      "path": "Courses/Machine Learning/CS234/CS234 Lecture 4.md"
    },
    {
      "basename": "Log-Likelihood Trick",
      "path": "Log-Likelihood Trick.md"
    },
    {
      "basename": "Epsilon-Greedy",
      "path": "Epsilon-Greedy.md"
    },
    {
      "basename": "Q-Function",
      "path": "Q-Function.md"
    },
    {
      "basename": "Multi-Armed Bandit",
      "path": "Multi-Armed Bandit.md"
    },
    {
      "basename": "Partial Observability",
      "path": "Partial Observability.md"
    },
    {
      "basename": "Mean Squared Error",
      "path": "Mean Squared Error.md"
    },
    {
      "basename": "RoBERTa",
      "path": "RoBERTa.md"
    },
    {
      "basename": "DeBERTa",
      "path": "DeBERTa.md"
    },
    {
      "basename": "BERT",
      "path": "BERT.md"
    },
    {
      "basename": "Bellman Equation",
      "path": "Bellman Equation.md"
    },
    {
      "basename": "Function Approximation",
      "path": "Function Approximation.md"
    },
    {
      "basename": "CS234 Vocabulary (+David Silver)",
      "path": "Courses/Machine Learning/CS234/CS234 Vocabulary (+David Silver).md"
    },
    {
      "basename": "SARSA",
      "path": "SARSA.md"
    },
    {
      "basename": "Generalized Policy Iteration",
      "path": "Generalized Policy Iteration.md"
    },
    {
      "basename": "Temporal Difference Learning",
      "path": "Temporal Difference Learning.md"
    },
    {
      "basename": "Q-Learning",
      "path": "Q-Learning.md"
    },
    {
      "basename": "Monte-Carlo Learning",
      "path": "Monte-Carlo Learning.md"
    },
    {
      "basename": "Conditional Random Field",
      "path": "Conditional Random Field.md"
    },
    {
      "basename": "Monte-Carlo",
      "path": "Monte-Carlo.md"
    },
    {
      "basename": "Policy Improvement",
      "path": "Policy Improvement.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}