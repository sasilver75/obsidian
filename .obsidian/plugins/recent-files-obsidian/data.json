{
  "recentFiles": [
    {
      "basename": "UltraChat",
      "path": "UltraChat.md"
    },
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "WizardMath",
      "path": "WizardMath.md"
    },
    {
      "basename": "Proximal Policy Optimization",
      "path": "Proximal Policy Optimization.md"
    },
    {
      "basename": "Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning",
      "path": "Papers/Process Reward Models/Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning.md"
    },
    {
      "basename": "Solving math word problems with process- and outcome-based feedback",
      "path": "Papers/Process Reward Models/Solving math word problems with process- and outcome-based feedback.md"
    },
    {
      "basename": "Let's Verify Step by Step",
      "path": "Papers/Process Reward Models/Let's Verify Step by Step.md"
    },
    {
      "basename": "Auto Evol-Instruct",
      "path": "Auto Evol-Instruct.md"
    },
    {
      "basename": "Reinforcement Learning from Evol-Instruct Feedback",
      "path": "Reinforcement Learning from Evol-Instruct Feedback.md"
    },
    {
      "basename": "MATH",
      "path": "MATH.md"
    },
    {
      "basename": "Reward Model",
      "path": "Reward Model.md"
    },
    {
      "basename": "Process Reward Model",
      "path": "Process Reward Model.md"
    },
    {
      "basename": "WizardLM",
      "path": "WizardLM.md"
    },
    {
      "basename": "Representation Finetuning",
      "path": "Representation Finetuning.md"
    },
    {
      "basename": "Claude",
      "path": "Claude.md"
    },
    {
      "basename": "Expert Iteration",
      "path": "Expert Iteration.md"
    },
    {
      "basename": "Rejection Sampling",
      "path": "Rejection Sampling.md"
    },
    {
      "basename": "t",
      "path": "t.md"
    },
    {
      "basename": "Chinchilla",
      "path": "Chinchilla.md"
    },
    {
      "basename": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation - A Survey",
      "path": "Papers/Synthetic Data/On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation - A Survey.md"
    },
    {
      "basename": "AlpaGasus",
      "path": "AlpaGasus.md"
    },
    {
      "basename": "AutoGPT",
      "path": "AutoGPT.md"
    },
    {
      "basename": "WizardArena",
      "path": "WizardArena.md"
    },
    {
      "basename": "~ Ideas",
      "path": "~ Ideas.md"
    },
    {
      "basename": "MosaicML",
      "path": "MosaicML.md"
    },
    {
      "basename": "~ Todo",
      "path": "~ Todo.md"
    },
    {
      "basename": "Best Practices and Lessons Learned on Synthetic Data for Language Models",
      "path": "Papers/Synthetic Data/Best Practices and Lessons Learned on Synthetic Data for Language Models.md"
    },
    {
      "basename": "The Rise of Agentic Data Generation (July 15, 2024) {Maximme Labonne}",
      "path": "Articles/The Rise of Agentic Data Generation (July 15, 2024) {Maximme Labonne}.md"
    },
    {
      "basename": "AgentInstruct",
      "path": "AgentInstruct.md"
    },
    {
      "basename": "Hallucination",
      "path": "Hallucination.md"
    },
    {
      "basename": "ROC-AUC",
      "path": "ROC-AUC.md"
    },
    {
      "basename": "ROC Curve",
      "path": "ROC Curve.md"
    },
    {
      "basename": "BabyAGI",
      "path": "BabyAGI.md"
    },
    {
      "basename": "TextGrad",
      "path": "TextGrad.md"
    },
    {
      "basename": "DataComp-LM",
      "path": "DataComp-LM.md"
    },
    {
      "basename": "Active Learning",
      "path": "Active Learning.md"
    },
    {
      "basename": "GenQA",
      "path": "GenQA.md"
    },
    {
      "basename": "AlpacaEval",
      "path": "AlpacaEval.md"
    },
    {
      "basename": "FLAN-T5",
      "path": "FLAN-T5.md"
    },
    {
      "basename": "Orca",
      "path": "Orca.md"
    },
    {
      "basename": "Self-Play Preference Optimization",
      "path": "Self-Play Preference Optimization.md"
    },
    {
      "basename": "Rejection Sampling Optimization",
      "path": "Rejection Sampling Optimization.md"
    },
    {
      "basename": "Prompting",
      "path": "Prompting.md"
    },
    {
      "basename": "Bradley-Terry Model",
      "path": "Bradley-Terry Model.md"
    },
    {
      "basename": "Direct Preference Optimization",
      "path": "Direct Preference Optimization.md"
    },
    {
      "basename": "Gemma 2",
      "path": "Gemma 2.md"
    },
    {
      "basename": "LIMA",
      "path": "LIMA.md"
    },
    {
      "basename": "FLAN",
      "path": "FLAN.md"
    },
    {
      "basename": "Preference Optimization with Identity Mapping",
      "path": "Preference Optimization with Identity Mapping.md"
    },
    {
      "basename": "Model Merging",
      "path": "Model Merging.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}