{
  "recentFiles": [
    {
      "basename": "01a Literature Review",
      "path": "Projects/Cohere Reasoning/Meetings/01a Literature Review.md"
    },
    {
      "basename": "Process Reward Model",
      "path": "Process Reward Model.md"
    },
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "Large Language Models Cannot Self-Correct Reasoning Yet",
      "path": "Papers/Long-Inference and Prompting/Large Language Models Cannot Self-Correct Reasoning Yet.md"
    },
    {
      "basename": "Shepherd",
      "path": "Shepherd.md"
    },
    {
      "basename": "Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning",
      "path": "Papers/Process Reward Models/Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning.md"
    },
    {
      "basename": "InstructGPT",
      "path": "InstructGPT.md"
    },
    {
      "basename": "GPT-J",
      "path": "GPT-J.md"
    },
    {
      "basename": "BLOOM",
      "path": "BLOOM.md"
    },
    {
      "basename": "Reflexion",
      "path": "Reflexion.md"
    },
    {
      "basename": "Let's Verify Step by Step",
      "path": "Papers/Process Reward Models/Let's Verify Step by Step.md"
    },
    {
      "basename": "ReAct",
      "path": "ReAct.md"
    },
    {
      "basename": "FLAN-T5",
      "path": "FLAN-T5.md"
    },
    {
      "basename": "Quiet STaR",
      "path": "Quiet STaR.md"
    },
    {
      "basename": "Self-Taught Reasoner",
      "path": "Self-Taught Reasoner.md"
    },
    {
      "basename": "Gopher",
      "path": "Gopher.md"
    },
    {
      "basename": "GPT-3.5",
      "path": "GPT-3.5.md"
    },
    {
      "basename": "ChatGPT",
      "path": "ChatGPT.md"
    },
    {
      "basename": "GPT-2",
      "path": "GPT-2.md"
    },
    {
      "basename": "GPT-3",
      "path": "GPT-3.md"
    },
    {
      "basename": "Evol-Instruct",
      "path": "Evol-Instruct.md"
    },
    {
      "basename": "Reinforcement Learning from Human Feedback",
      "path": "Reinforcement Learning from Human Feedback.md"
    },
    {
      "basename": "01 Kickoff Meeting Friday, August 30 1030AM",
      "path": "Projects/Cohere Reasoning/Meetings/01 Kickoff Meeting Friday, August 30 1030AM.md"
    },
    {
      "basename": "Hydra",
      "path": "Hydra.md"
    },
    {
      "basename": "Index",
      "path": "Projects/Cohere Reasoning/Index.md"
    },
    {
      "basename": "~ Followup",
      "path": "~ Followup.md"
    },
    {
      "basename": "Qwen 2 VL",
      "path": "Qwen 2 VL.md"
    },
    {
      "basename": "~ Useful Pictures",
      "path": "~ Useful Pictures.md"
    },
    {
      "basename": "Speculative Decoding",
      "path": "Speculative Decoding.md"
    },
    {
      "basename": "Better and Faster Large Language Models via Multi-token Prediction",
      "path": "Papers/General/Better and Faster Large Language Models via Multi-token Prediction.md"
    },
    {
      "basename": "EAGLE",
      "path": "EAGLE.md"
    },
    {
      "basename": "Gemma 2",
      "path": "Gemma 2.md"
    },
    {
      "basename": "Medusa",
      "path": "Medusa.md"
    },
    {
      "basename": "Omar Khattab",
      "path": "Omar Khattab.md"
    },
    {
      "basename": "A recipe for Frontier Model Post-Training (August 7, 2024) {Nathan Lambert}",
      "path": "Articles/A recipe for Frontier Model Post-Training (August 7, 2024) {Nathan Lambert}.md"
    },
    {
      "basename": "Why I bet on DSPy (August 10, 2024) {Isaac Miller}",
      "path": "Articles/Why I bet on DSPy (August 10, 2024) {Isaac Miller}.md"
    },
    {
      "basename": "AgentInstruct 2024-07-12 15.36.46.excalidraw",
      "path": "_attachments/AgentInstruct 2024-07-12 15.36.46.excalidraw.md"
    },
    {
      "basename": "Constitutional AI",
      "path": "Constitutional AI.md"
    },
    {
      "basename": "~ Ideas",
      "path": "~ Ideas.md"
    },
    {
      "basename": "Automatically Correcting Large Language Models - Surveying the landscape of diverse self-correction techniques",
      "path": "Papers/General/Automatically Correcting Large Language Models - Surveying the landscape of diverse self-correction techniques.md"
    },
    {
      "basename": "Continued Pretraining",
      "path": "Continued Pretraining.md"
    },
    {
      "basename": "LLaMA 3.1",
      "path": "LLaMA 3.1.md"
    },
    {
      "basename": "Quantization",
      "path": "Quantization.md"
    },
    {
      "basename": "ChatBot Arena",
      "path": "ChatBot Arena.md"
    },
    {
      "basename": "Bradley-Terry-Luce Model",
      "path": "Bradley-Terry-Luce Model.md"
    },
    {
      "basename": "Self-Instruct",
      "path": "Self-Instruct.md"
    },
    {
      "basename": "DeepSeekMath",
      "path": "DeepSeekMath.md"
    },
    {
      "basename": "Apple Intelligence Foundation Language Models",
      "path": "Papers/General/Apple Intelligence Foundation Language Models.md"
    },
    {
      "basename": "~ Recommendations",
      "path": "~ Recommendations.md"
    },
    {
      "basename": "Self-Play Fine-Tuning",
      "path": "Self-Play Fine-Tuning.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}