{
  "recentFiles": [
    {
      "basename": "Better and Faster Large Language Models via Multi-token Prediction",
      "path": "Papers/General/Better and Faster Large Language Models via Multi-token Prediction.md"
    },
    {
      "basename": "UltraChat",
      "path": "UltraChat.md"
    },
    {
      "basename": "What we learned from a Year of Building with LLMs (Part 1) (May 28, 2024) {Eugene Yan, Bryan Bischof, Charles Frye, Hamel Husain, Jason Liu, Shreya Shankar}",
      "path": "Articles/What we learned from a Year of Building with LLMs (Part 1) (May 28, 2024) {Eugene Yan, Bryan Bischof, Charles Frye, Hamel Husain, Jason Liu, Shreya Shankar}.md"
    },
    {
      "basename": "Medusa",
      "path": "Medusa.md"
    },
    {
      "basename": "~ Ideas",
      "path": "~ Ideas.md"
    },
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "FLAN v2",
      "path": "FLAN v2.md"
    },
    {
      "basename": "Shepherd",
      "path": "Shepherd.md"
    },
    {
      "basename": "Reinforcement Learning from from AI Feedback",
      "path": "Reinforcement Learning from from AI Feedback.md"
    },
    {
      "basename": "UltraFeedback",
      "path": "UltraFeedback.md"
    },
    {
      "basename": "GPT-4",
      "path": "GPT-4.md"
    },
    {
      "basename": "Orca",
      "path": "Orca.md"
    },
    {
      "basename": "Evol-Instruct",
      "path": "Evol-Instruct.md"
    },
    {
      "basename": "UltraLLaMA",
      "path": "UltraLLaMA.md"
    },
    {
      "basename": "WizardLM",
      "path": "WizardLM.md"
    },
    {
      "basename": "Let's Verify Step by Step",
      "path": "Papers/Process Reward Models/Let's Verify Step by Step.md"
    },
    {
      "basename": "Process Reward Model",
      "path": "Process Reward Model.md"
    },
    {
      "basename": "Reward Model",
      "path": "Reward Model.md"
    },
    {
      "basename": "Reinforcement Learning from Evol-Instruct Feedback",
      "path": "Reinforcement Learning from Evol-Instruct Feedback.md"
    },
    {
      "basename": "Auto Evol-Instruct",
      "path": "Auto Evol-Instruct.md"
    },
    {
      "basename": "Solving math word problems with process- and outcome-based feedback",
      "path": "Papers/Process Reward Models/Solving math word problems with process- and outcome-based feedback.md"
    },
    {
      "basename": "Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning",
      "path": "Papers/Process Reward Models/Let's Reward Step by Step; Step-Level Reward Model as the Navigator for Reasoning.md"
    },
    {
      "basename": "WizardMath",
      "path": "WizardMath.md"
    },
    {
      "basename": "Proximal Policy Optimization",
      "path": "Proximal Policy Optimization.md"
    },
    {
      "basename": "MATH",
      "path": "MATH.md"
    },
    {
      "basename": "Representation Finetuning",
      "path": "Representation Finetuning.md"
    },
    {
      "basename": "Claude",
      "path": "Claude.md"
    },
    {
      "basename": "Expert Iteration",
      "path": "Expert Iteration.md"
    },
    {
      "basename": "Rejection Sampling",
      "path": "Rejection Sampling.md"
    },
    {
      "basename": "t",
      "path": "t.md"
    },
    {
      "basename": "Chinchilla",
      "path": "Chinchilla.md"
    },
    {
      "basename": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation - A Survey",
      "path": "Papers/Synthetic Data/On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation - A Survey.md"
    },
    {
      "basename": "AlpaGasus",
      "path": "AlpaGasus.md"
    },
    {
      "basename": "AutoGPT",
      "path": "AutoGPT.md"
    },
    {
      "basename": "WizardArena",
      "path": "WizardArena.md"
    },
    {
      "basename": "MosaicML",
      "path": "MosaicML.md"
    },
    {
      "basename": "~ Todo",
      "path": "~ Todo.md"
    },
    {
      "basename": "Best Practices and Lessons Learned on Synthetic Data for Language Models",
      "path": "Papers/Synthetic Data/Best Practices and Lessons Learned on Synthetic Data for Language Models.md"
    },
    {
      "basename": "The Rise of Agentic Data Generation (July 15, 2024) {Maximme Labonne}",
      "path": "Articles/The Rise of Agentic Data Generation (July 15, 2024) {Maximme Labonne}.md"
    },
    {
      "basename": "AgentInstruct",
      "path": "AgentInstruct.md"
    },
    {
      "basename": "Hallucination",
      "path": "Hallucination.md"
    },
    {
      "basename": "ROC-AUC",
      "path": "ROC-AUC.md"
    },
    {
      "basename": "ROC Curve",
      "path": "ROC Curve.md"
    },
    {
      "basename": "BabyAGI",
      "path": "BabyAGI.md"
    },
    {
      "basename": "TextGrad",
      "path": "TextGrad.md"
    },
    {
      "basename": "DataComp-LM",
      "path": "DataComp-LM.md"
    },
    {
      "basename": "Active Learning",
      "path": "Active Learning.md"
    },
    {
      "basename": "GenQA",
      "path": "GenQA.md"
    },
    {
      "basename": "AlpacaEval",
      "path": "AlpacaEval.md"
    },
    {
      "basename": "FLAN-T5",
      "path": "FLAN-T5.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}