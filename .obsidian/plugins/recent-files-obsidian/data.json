{
  "recentFiles": [
    {
      "basename": "~ Vocabulary",
      "path": "~ Vocabulary.md"
    },
    {
      "basename": "Decoding Strategies in Large Language Models",
      "path": "Articles/Decoding Strategies in Large Language Models.md"
    },
    {
      "basename": "Untitled 2",
      "path": "Untitled 2.md"
    },
    {
      "basename": "GPTQ",
      "path": "GPTQ.md"
    },
    {
      "basename": "Data-Centric AI (3) - Dataset Creation and Curation",
      "path": "Courses/MIT Introduction to Data-Centric AI (2023)/Data-Centric AI (3) - Dataset Creation and Curation.md"
    },
    {
      "basename": "Selection Bias",
      "path": "Selection Bias.md"
    },
    {
      "basename": "t-SNE",
      "path": "t-SNE.md"
    },
    {
      "basename": "Diffusion Transformer",
      "path": "Diffusion Transformer.md"
    },
    {
      "basename": "Introduction to Weight Quantization (July 7, 2023) {Maxime Labonne}",
      "path": "Articles/Introduction to Weight Quantization (July 7, 2023) {Maxime Labonne}.md"
    },
    {
      "basename": "~ Ideas",
      "path": "~ Ideas.md"
    },
    {
      "basename": "Synthetic Data",
      "path": "Synthetic Data.md"
    },
    {
      "basename": "Q-Learning",
      "path": "Q-Learning.md"
    },
    {
      "basename": "SARSA",
      "path": "SARSA.md"
    },
    {
      "basename": "Temporal Difference Learning",
      "path": "Temporal Difference Learning.md"
    },
    {
      "basename": "David Silver RL (6) - Value Function Approximation",
      "path": "Courses/David Silver UCL Reinforcement Learning/David Silver RL (6) - Value Function Approximation.md"
    },
    {
      "basename": "David Silver RL (5) -  Model-Free Control",
      "path": "Courses/David Silver UCL Reinforcement Learning/David Silver RL (5) -  Model-Free Control.md"
    },
    {
      "basename": "LLM.int8()",
      "path": "LLM.int8().md"
    },
    {
      "basename": "Absolute Maximum Quantization",
      "path": "Absolute Maximum Quantization.md"
    },
    {
      "basename": "Zero-Point Quantization",
      "path": "Zero-Point Quantization.md"
    },
    {
      "basename": "Zero-Shot Prompting",
      "path": "Zero-Shot Prompting.md"
    },
    {
      "basename": "Claude",
      "path": "Claude.md"
    },
    {
      "basename": "Dynabench",
      "path": "Dynabench.md"
    },
    {
      "basename": "Gemma 2",
      "path": "Gemma 2.md"
    },
    {
      "basename": "Distillation",
      "path": "Distillation.md"
    },
    {
      "basename": "SB-1047",
      "path": "SB-1047.md"
    },
    {
      "basename": "Support Vector Machine",
      "path": "Support Vector Machine.md"
    },
    {
      "basename": "bfloat16",
      "path": "bfloat16.md"
    },
    {
      "basename": "float16",
      "path": "float16.md"
    },
    {
      "basename": "float32",
      "path": "float32.md"
    },
    {
      "basename": "INT8",
      "path": "INT8.md"
    },
    {
      "basename": "Direct Preference Optimization",
      "path": "Direct Preference Optimization.md"
    },
    {
      "basename": "~ Useful Pictures",
      "path": "~ Useful Pictures.md"
    },
    {
      "basename": "Padding",
      "path": "Padding.md"
    },
    {
      "basename": "Nemotron-4",
      "path": "Nemotron-4.md"
    },
    {
      "basename": "Zephyr",
      "path": "Zephyr.md"
    },
    {
      "basename": "LLaMA 2",
      "path": "LLaMA 2.md"
    },
    {
      "basename": "UltraInteract",
      "path": "UltraInteract.md"
    },
    {
      "basename": "IFEval",
      "path": "IFEval.md"
    },
    {
      "basename": "Weak-to-Strong Generalization",
      "path": "Weak-to-Strong Generalization.md"
    },
    {
      "basename": "GenQA",
      "path": "GenQA.md"
    },
    {
      "basename": "Hybrid Search",
      "path": "Hybrid Search.md"
    },
    {
      "basename": "Reward Model",
      "path": "Reward Model.md"
    },
    {
      "basename": "Best-of-N Sampling",
      "path": "Best-of-N Sampling.md"
    },
    {
      "basename": "Rejection Sampling",
      "path": "Rejection Sampling.md"
    },
    {
      "basename": "Markov Assumption",
      "path": "Markov Assumption.md"
    },
    {
      "basename": "Model Predictive Control",
      "path": "Model Predictive Control.md"
    },
    {
      "basename": "Process Reward Model",
      "path": "Process Reward Model.md"
    },
    {
      "basename": "Deep Reinforcement Learning Doesn't Work Yet (Feb 14, 2018) {Sorta Insightful Blog}",
      "path": "Articles/Deep Reinforcement Learning Doesn't Work Yet (Feb 14, 2018) {Sorta Insightful Blog}.md"
    },
    {
      "basename": "Reward",
      "path": "Reward.md"
    },
    {
      "basename": "The Q* Hypothesis - Tree of Thoughts reasoning, process reward models, and supercharging synthetic data (November 24, 2023) {Nathan Lambert}",
      "path": "Articles/The Q* Hypothesis - Tree of Thoughts reasoning, process reward models, and supercharging synthetic data (November 24, 2023) {Nathan Lambert}.md"
    }
  ],
  "omittedPaths": [],
  "maxLength": null,
  "openType": "tab"
}