https://www.interconnects.ai/p/building-on-evaluation-quicksand
----

The landscape of evalaution of LLMs hasn't changed substantially in the last year or so.

New types of models that [[OpenAI]]'s [[o1]] models herald welcome a new axis to this -- evalaution-time compute.

This article tracks four trends in evaluation that I've been following:
1. How ==leading frontier labs have shifting needs for evaluation==
2. How ==open-source efforts should standardize and collaborate on evaluation.==
3. ==Contamination== affects evaluation results and best practices.
4. ==Inference-compute constant evaluations== and pushing the bar up for the hardest evals.

All of these result in unexpected traps at every turn when you try to build language models.
- Traps that go deep
- Traps whose effects are hard to predict on your outputs.

What used to be solid, simple ground in evaluations now feels like quicksand.

The causes of today's evaluation silos:
- Evaluations done within companies can only be compared to peers with large error bars.
- Evaluation scores have become central components of ==marketing schemes==, which impacts implementations within companies (basically, cheating.)
- Open source community hasn't converged on a single rubric for evaluation of language models.

When result are shared from inside frontier labs, all we get are the numbers that a lab got for their models, but not the inputs to that function. ==The inputs are VERY sensitive configurations, and they're different at all of OpenAI, Meta, Anthropic, Google,== and they are usually ==NOT DISCLOSED!==


Inflection
- Woman -> women
- YOLO -> YOLOing
- medium -> media
- datum -> data
- run -> runs

Deriviation
- form -> formal (he didn't agree with it but that's right)
- compute -> computer
- morph, morphology
- careful, carefulness

Compounding
- overcook
- cardboard
- ductape
- bigfoot
- popcorn
- daylight

Clitic
- Ne'erdowell -> Never do well (noun, person)
- I'mma -> I'm gonna -> I'm going to


==Gloss (linguistics)==
- A series of brief explanations, like definitions and morphological analysis for each wor,d placed between a sentence and its translation to a ifferent language.


