#article 
Link:  https://newsletter.ruder.io/p/thoughts-on-the-2024-ai-job-market

-----

It's crazy how the AI/NLP landscape has evolved; [[Sebastian Ruder]] (author) has just joined the company [[Cohere]].

# AI Job Market Trends


## 1. Research has become more applied
- Most of the problems in the past of ML and NLP were firmly in the purview of fundamental or basic research. Models weren't powerful enough, and datasets reflected simplified evaluation settings that were feasible at the time and typically far removed from applications.
- Today, models have become more powerful, and the gap between fundamental and appleid research in NLP has consistently narrowed. 
- Problems that were previously in the domain of basic research now impact real-world applications, after the emergence of pre-training (NLP's ImageNet moment). This means that new advances in research have the ability to have a broad impact, and that researchers must consider challenges regarding the safe and responsible use of such technology.
- When much other research has immediate product impact, how can you justify working on an unproven direction? Researchers need to balance short-term impact with long-term research potential, with the scale tilting to the former.


## 2. Startups are a serious alternative to a PhD
- Startups -- particularly early-stage ones, aren't for everyone -- they require a person with a certain type of mindset and motivation, who enjoys solving real-world problems and having a tangible, direct impact; who can work autonomously and without much guidance; who thrives in a hectic, unstructured environment and can handle ambiguity.
- ==If you're comfortable in the above conditions, you can acquire certain skills and knowledge much faster tan in a typical PHD -- and you'll get hands-on experience with emerging methodologies like instruction and preference-tuning, red-teaming, LLM alignment, etc.==
	- A PhD is likely still the best option if you want to follow your own curiosity and focus on your personal development -- and if you value collaboration and mentorship, or being creative and coming up with genuinely new ideas.


## 3. ML has become less open and more polarized
- Early pre-trained models like [[ELMo]], [[Bidirectional Encoder Representations from Transformers|BERT]], [[GPT]], and [[T5]] were open-sourced, enabling widespread adoption
- Over time, this radical openness have shifted -- models like [[GPT-3]] and [[PaLM]] were increasingly locked behinds APIs, but the papers still described the architecture in detail.
- After that generation, more recent models like [[GPT-4]] and [[PaLM 2]] and [[Gemeni]] aren't just closed-source, but their papers reveal very little about the architecture and training data!

This lack of knowledge sharing may impede progress in AI development
- Open source models like [[BLOOM]] and [[OLMo]] and [[Pythia]] are all truly open -- and a few companies (eg FB, MSFT) have showed some renewed commitment to open-source.


## 4. Research is concentrated in large projects
- LLM projects not only require people with research skills, but also strong software engineers that can design systems that scale to 100s of billions of parameters and trillions of tokens.
- ==LLMS require disparate sets of expertise, including data processing, optimization, fine-tuning, RL, evaluation, safety, infrastructure, multi-modality, etc.==
- As a result, the size of teams working on the latest generation of LLMs has rapidly increased.


# 5. More companies, more opportunities
- The advent of LLMs led to a wave of new companies leveraging this technology, and prompted existing companies to figure out how to incorporate these models into their products.
- YC has funded more than 100 GenAI startups, but this is just the beginning.
- Many research challenges remain
	- Mitigating hallucinations
	- Ensuring trustworthiness and attribution
	- Aligning models to reliably elicit desired behavior
	- Ensuring robust reasoning, etc.















