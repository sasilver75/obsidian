https://www.interconnects.ai/p/why-i-build-open-language-models
[[Nathan Lambert|Nato]]

-----

The deepest motivations for the passion of open-source IA are fears of AI development going wrong
- Rhymes with recommender systems, social networks, and internet writ large damages... not stories of bad actors, but negligent actors, deploying powerful technologies in ways that become nefarious without oversight.

Our central models, [[OLMo]]s, are best understood as research infrastructure more than just standalone artifacts.
- Still, he thinks that the dataset behind our first multimodal language model, Molmo, gets some things right that the frontier labs don't seen to have cracked.

The more opinionated lens for the Allen Institute is what OpenAI originally seemed they were going to be.

In terms of chasing capabilities, AI2 is barely staying about the waterline...
RLHF is about desirable behaviors for users, and exotic models like o1.

There are not many true allies of open-source AI...
There's a lot of room for impact in training open models.
By bending the curve now of the open, we are determining if there can bean open-source AI in the future.
We need more people willing to fight this fight.

At AI2, a small handful of people drive most of the progress on OLMo.

As we gain momentum, more are joining, but it only happens when the point clicks in their head.
The opportunities afforded to individuals are some of the most straightforward paths to major impact I expect to see in my career, but they're not the traditional paths that we've been trained on.

 We don’t have an evaluation for an important part of the alignment process — let’s build a benchmark. All the closed labs are approaching RLHF differently than academics — let’s just do what the closed labs are doing and share it. What is “next” after that is to be determined in 2025.

If this is you, please get in touch whether or not Allen Institute is the exact open place you end up at. It’s been very fun and I’m just going to keep going. I have some new stuff to share very soon.























