---
excalidraw-plugin:
---
https://www.interconnects.ai/p/saving-the-nairr?utm_source=post-email-title&publication_id=48206&post_id=151441789&utm_campaign=email-post-title&isFreemail=true&r=764e6&triedRedirect=true&utm_medium=email

[[Nathan Lambert|Nato]]

----

The Trump administration now has us staring down the barrel of starting over on AI policy at the federal levle.

Nato wants to make he case for the [[National AI Research Resource]] (NAIRR)

![[Pasted image 20241113202106.png]]

NAIRR is positioned as a major bridge between:
- Federal government
- Large tech companies
- Scientific institutions in the US

It was started in the Biden Administration's 2023 Executive Order on AI

> Within 90 days of the date of this order, in coordination with the heads of agencies that the Director of NSF deems appropriate, launch a pilot program implementing the National AI Research Resource (NAIRR), consistent with past recommendations of the NAIRR Task Force. ==**The program shall pursue the infrastructure, governance mechanisms, and user interfaces to pilot an initial integration of distributed computational, data, model, and training resources to be made available to the research community in support of AI-related research and development==.** The Director of NSF shall identify Federal and private sector computational, data, software, and training resources appropriate for inclusion in the NAIRR pilot program.

NAIRR is not about training "USA-GPT", rather it's for building infrastructure that others can use to build, understand, and use cutting-edge language models.
- Government could easily mobilize low billions of dollars for AI resources.

> To assist with such work, within 45 days of the date of this order, the heads of agencies whom the Director of NSF identifies for coordination pursuant to this subsection shall each submit to the Director of NSF a report identifying the agency resources that could be developed and integrated into such a pilot program.

In the last year, the NAIRR has done a lot of hard work on procurement. This looks like compute and credits from the biggest technology companies and AI labs combined with data and resources from federal agencies. I’ve benefited from API credits in the NAIRR pilot program for my work — it’s nowhere near a major amount of compute, but a good example of where the money goes.

Doing NAIRR in 5 years, rather than today, may just not be useful for the outcomes that motivate it.

NAIRR is poised to go away, and with it, a large opportunity to balance the research ecosystem.

I worry scenarios alternate to NAIRR-style approaches like the new administration is going to spend some of its precious resources building a language model, when it should be enabling the existing academic and non-profit ecosystem to do it _with_ them.

I haven’t commented on NAIRR because it is obviously imperfect. I wanted to see it refined, clarified, and matured, but the parties at play weren’t clear to me. ==Now, it is clear as day that a world without NAIRR could set back the academic AI ecosystem by months to years==.

## Do we need an AI research resource or an LM research resourceS?

Things we might want:
1. ==Transparency into techniques powering== state-of-the-art AI tools, so we can inform better policy.
2. Resources for third-party ==evaluation and testing of closed models==.
3. Resources to ==enable academic and non-Big Tech participation== in understanding this new technology.
4. Resources to enable the economy of AI to work on longer timescales through ==sustainable, breakthrough research==.
5. Resources to ==enable the open-source ecosystem== to enable the benefits that come with it.

There is a large history in CS research of throwing a new technique at an old problem and _saying_ it is better with “novel research” when in reality the new method is marginally better and or worse. ==How do we make the new programs focused on narrower projects that actually improve outcomes and transparency for the public?== How do we prioritize AI research specifically versus applications AI research (it seems like a lot of work is on the latter)?

We deal with this a lot internally at Ai2. It is trying to navigate the discussion of who should actually get compute. ==It is a straining question to need to directly tell people their work is not valuable by stating their resource allocations==. ==The process does not work without clearly stating priorities== — something that has tended not to be needed in a previous, slower, era of AI development.

==This type of control is why I tend to be opposed to the phrase _democratizing AI_==. By definition, control of this sort is not democratic. ==Public initiatives for AI are about supporting the public, not about public access to all of AI.== It is especially not realistic to expect the public to control the future trajectories of AI, which would be actual democratic influence.
- ((It's not that everyone gets to play -- not that everyone just gets to spend money on shit willy nilly))


## Policy

State legislation risks
-  Academia has a huge exposure risk to open-source, and partially open models like Llama, being hindered by sloppy legislation. 

Elon v Trump on AI Safety
- Elon endorsed SB 1047
- Trump was more of a deregulation guy
- Big tech elites that pushed for trump are too
- Who will win over Trump's views?

AI Agents are real and coming
- OpenAI’s o1 and Claude’s Computer Use opened up one-way doors to much weirder needs for regulation
- Regulating agents will take a much more nuanced understanding of our internet economy and is one of the policy angles I’m most excited about exploring















