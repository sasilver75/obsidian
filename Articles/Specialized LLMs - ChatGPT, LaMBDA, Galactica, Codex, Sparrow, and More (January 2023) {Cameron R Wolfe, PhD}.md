#article 
Link: https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica

-----

In this overview, we'll explore methods of replacing and improving LLMs for a variety of use-cases.

We can modify the behavior of LLMs by using techniques like:
1. Domain-specific pretraining (eg BloombergGPT)
2. [[Supervised Fine-Tuning]]
3. Model alignment (eg via [[Reinforcement Learning from Human Feedback|RLHF]])

These methods can be used to combat known limitations of LLMs and modify them to better suit our needs, through either/both behavior and knowledge.

(Skipping some descriptions of "what are language models," etc.)

# Publications
Now let's overview a variety of publications that extend generic LLMs to more specialized scenarios. Numerous different methodologies are used to modify and improve LLMs, but the general concept is the same.

### Evaluating Large Language Models Trained on Code
- ...












