https://www.youtube.com/watch?v=h1c_jmk97Ss

Speaker: Emmanual Ameisen (Research Engineer @ Anthropic)

TLDR: "I've been training models for 10 years; I don't recommend it."

----

Agenda
1. Trends
2. Performance
3. Difficulty


One of the best ways to have a lot of impact in ML is to be afraid of anything that sounds cool. 
- Usually, these things are vaporware.

In 2009: People wanted to train models, but they really should have been writing good SQL queries.
In 2013: People wanted to use deep learning, but they really should have been using XGBoost
In 2015: People wanted to invent a new loss function, or a new optimizer, but really they should have cleaned their dataset and removed obvious errors to get more improvement with less effort.
In 2023/2024: People want to train their own LLMs (or finetune), but really what they should be doing is making better prompts. It's rarely the first thing you should reach for.


![[Pasted image 20240702222221.png]]

![[Pasted image 20240702223108.png]]
From the OpenAI forum (of what happens in some cases, but not all)
- Finetune didn't seem to do any better?...
- Context injection (basically RAG)
- Various different models...

Really not a lot going on in this talk at all.

![[Pasted image 20240702224606.png]]

![[Pasted image 20240702224644.png]]





